2016-10-27 15:00:30 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-10-27 15:00:30 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-27 15:00:30 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-10-27 15:00:30 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-10-27 15:00:30 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-10-27 15:00:30 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-10-27 15:00:30 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-10-27 15:00:31 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 52228.
2016-10-27 15:00:31 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-10-27 15:00:31 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-10-27 15:00:31 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-5fa76dae-d561-4535-a301-9efd2671cf61
2016-10-27 15:00:31 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-10-27 15:00:31 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-10-27 15:00:31 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @2684ms
2016-10-27 15:00:31 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-10-27 15:00:32 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:00:32 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2898ms
2016-10-27 15:00:32 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-10-27 15:00:32 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-10-27 15:00:32 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-10-27 15:00:32 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52229.
2016-10-27 15:00:32 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:52229
2016-10-27 15:00:32 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 52229)
2016-10-27 15:00:32 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:52229 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 52229)
2016-10-27 15:00:32 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 52229)
2016-10-27 15:00:33 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-10-27 15:00:33 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-10-27 15:00:33 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:52229 (size: 10.2 KB, free: 912.3 MB)
2016-10-27 15:00:33 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkJavaRDD.java:25
2016-10-27 15:00:33 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-10-27 15:00:33 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:45
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 3 (mapToPair at SparkJavaRDD.java:42)
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (sortByKey at SparkJavaRDD.java:45) with 2 output partitions
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 0)
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 0)
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:42), which has no missing parents
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
2016-10-27 15:00:33 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:52229 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:42)
2016-10-27 15:00:33 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_0 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_1 stored as values in memory (estimated size 4.9 KB, free 912.2 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_0 in memory on 172.16.106.190:52229 (size: 5.7 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_1 in memory on 172.16.106.190:52229 (size: 4.9 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 2262 bytes result sent to driver
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 2262 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 292 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 244 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 0 (mapToPair at SparkJavaRDD.java:42) finished in 0.320 s
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 1)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[6] at sortByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 4.6 KB, free 912.2 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.2 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:52229 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, ANY, 5142 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, ANY, 5142 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 7 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2394 bytes result sent to driver
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2411 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 77 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 84 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (sortByKey at SparkJavaRDD.java:45) finished in 0.085 s
2016-10-27 15:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: sortByKey at SparkJavaRDD.java:45, took 0.644217 s
2016-10-27 15:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkJavaRDD.java:46
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 4 (reduceByKey at SparkJavaRDD.java:45)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (collect at SparkJavaRDD.java:46) with 2 output partitions
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (collect at SparkJavaRDD.java:46)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 3)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 3)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 3 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 4.3 KB, free 912.2 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.2 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:52229 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 3 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:45)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 4)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 3.0 (TID 5)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 3.0 (TID 5). 1882 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 3.0 (TID 5) in 43 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4). 1882 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4) in 47 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 3 (reduceByKey at SparkJavaRDD.java:45) finished in 0.048 s
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 4)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.0 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:52229 (size: 2.0 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 4 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 3896 bytes result sent to driver
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 4186 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 28 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 30 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (collect at SparkJavaRDD.java:46) finished in 0.031 s
2016-10-27 15:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: collect at SparkJavaRDD.java:46, took 0.113242 s
2016-10-27 15:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:48
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (sortByKey at SparkJavaRDD.java:48) with 2 output partitions
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 7 (sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 6)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 7 (MapPartitionsRDD[10] at sortByKey at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:52229 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[10] at sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 8, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 7.0 (TID 9, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 8)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 7.0 (TID 9)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 7.0 (TID 9). 2255 bytes result sent to driver
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 8). 2235 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 7.0 (TID 9) in 14 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 8) in 17 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 7 (sortByKey at SparkJavaRDD.java:48) finished in 0.018 s
2016-10-27 15:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: sortByKey at SparkJavaRDD.java:48, took 0.032890 s
2016-10-27 15:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:49
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (mapToPair at SparkJavaRDD.java:48)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (foreach at SparkJavaRDD.java:49) with 2 output partitions
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 11 (foreach at SparkJavaRDD.java:49)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 10)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 10)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 10 (MapPartitionsRDD[8] at mapToPair at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:52229 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[8] at mapToPair at SparkJavaRDD.java:48)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 10.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 10.0 (TID 11, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 10.0 (TID 11)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 10.0 (TID 10)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 10). 1882 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 10) in 27 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 10.0 (TID 11). 1882 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 10.0 (TID 11) in 27 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 10 (mapToPair at SparkJavaRDD.java:48) finished in 0.030 s
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 11)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 11 (ShuffledRDD[11] at sortByKey at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:52229 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 11 (ShuffledRDD[11] at sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 11.0 (TID 13, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 12)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 11.0 (TID 13)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12). 1640 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12) in 29 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13). 1553 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13) in 33 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 11 (foreach at SparkJavaRDD.java:49) finished in 0.035 s
2016-10-27 15:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: foreach at SparkJavaRDD.java:49, took 0.090030 s
2016-10-27 15:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:56
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 12 (mapToPair at SparkJavaRDD.java:54)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (sortByKey at SparkJavaRDD.java:56) with 2 output partitions
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 13 (sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 12)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 12)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 12 (MapPartitionsRDD[12] at mapToPair at SparkJavaRDD.java:54), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:52229 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[12] at mapToPair at SparkJavaRDD.java:54)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 12.0 (TID 15, localhost, partition 1, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 14)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 12.0 (TID 15)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_1 locally
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14). 1490 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14) in 29 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15). 1490 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15) in 29 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 12 (mapToPair at SparkJavaRDD.java:54) finished in 0.034 s
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 13)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 13 (MapPartitionsRDD[15] at sortByKey at SparkJavaRDD.java:56), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:52229 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[15] at sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 13.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 13.0 (TID 16, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 13.0 (TID 17, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 13.0 (TID 16)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 13.0 (TID 17)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 16). 1855 bytes result sent to driver
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 13.0 (TID 17). 1865 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 16) in 12 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 13.0 (TID 17) in 11 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 13 (sortByKey at SparkJavaRDD.java:56) finished in 0.013 s
2016-10-27 15:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: sortByKey at SparkJavaRDD.java:56, took 0.096033 s
2016-10-27 15:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkJavaRDD.java:57
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 3 is 159 bytes
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 13 (reduceByKey at SparkJavaRDD.java:56)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 5 (collect at SparkJavaRDD.java:57) with 2 output partitions
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 16 (collect at SparkJavaRDD.java:57)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 15)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 15)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 15 (ShuffledRDD[13] at reduceByKey at SparkJavaRDD.java:56), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:52229 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 15 (ShuffledRDD[13] at reduceByKey at SparkJavaRDD.java:56)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 15.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 15.0 (TID 18, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 15.0 (TID 19, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 15.0 (TID 18)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 15.0 (TID 19)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 2 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 18). 1882 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 18) in 16 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 19). 1882 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 19) in 16 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 15 (reduceByKey at SparkJavaRDD.java:56) finished in 0.018 s
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 16)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 16 (ShuffledRDD[16] at sortByKey at SparkJavaRDD.java:56), which has no missing parents
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 912.1 MB)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:52229 (size: 2.1 KB, free: 912.3 MB)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 16 (ShuffledRDD[16] at sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 16.0 with 2 tasks
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 16.0 (TID 20, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 16.0 (TID 21, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 16.0 (TID 20)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 16.0 (TID 21)
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:00:34 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 16.0 (TID 20). 1860 bytes result sent to driver
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:00:34 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 16.0 (TID 20) in 9 ms on localhost (1/2)
2016-10-27 15:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 16.0 (TID 21). 1834 bytes result sent to driver
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 16.0 (TID 21) in 14 ms on localhost (2/2)
2016-10-27 15:00:34 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-10-27 15:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 16 (collect at SparkJavaRDD.java:57) finished in 0.016 s
2016-10-27 15:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 5 finished: collect at SparkJavaRDD.java:57, took 0.072241 s
2016-10-27 15:00:34 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:00:34 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-10-27 15:00:34 INFO  [dispatcher-event-loop-0] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-10-27 15:00:34 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-10-27 15:00:34 INFO  [main] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-10-27 15:00:35 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-10-27 15:00:35 INFO  [dispatcher-event-loop-0] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-10-27 15:00:35 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-10-27 15:00:35 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-10-27 15:00:35 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-e01156e1-b29a-4fcd-bfba-0d19e3a82ea4
2016-10-27 15:14:17 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-10-27 15:14:18 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-10-27 15:14:18 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 52497.
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-10-27 15:14:18 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-6e08745a-e363-4e53-98e9-6f28f496901e
2016-10-27 15:14:18 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-10-27 15:14:18 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-10-27 15:14:19 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @2241ms
2016-10-27 15:14:19 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-10-27 15:14:19 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:14:19 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2395ms
2016-10-27 15:14:19 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-10-27 15:14:19 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-10-27 15:14:19 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-10-27 15:14:19 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52498.
2016-10-27 15:14:19 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:52498
2016-10-27 15:14:19 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 52498)
2016-10-27 15:14:19 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:52498 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 52498)
2016-10-27 15:14:19 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 52498)
2016-10-27 15:14:20 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-10-27 15:14:20 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-10-27 15:14:20 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:52498 (size: 10.2 KB, free: 912.3 MB)
2016-10-27 15:14:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkJavaRDD.java:25
2016-10-27 15:14:20 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-10-27 15:14:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:45
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 3 (mapToPair at SparkJavaRDD.java:42)
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (sortByKey at SparkJavaRDD.java:45) with 2 output partitions
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 0)
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 0)
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:42), which has no missing parents
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
2016-10-27 15:14:20 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:52498 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:42)
2016-10-27 15:14:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-10-27 15:14:20 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-10-27 15:14:20 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-10-27 15:14:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-10-27 15:14:20 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_1 stored as values in memory (estimated size 4.9 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_0 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_1 in memory on 172.16.106.190:52498 (size: 4.9 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_0 in memory on 172.16.106.190:52498 (size: 5.7 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 2262 bytes result sent to driver
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 2262 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 230 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 269 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 0 (mapToPair at SparkJavaRDD.java:42) finished in 0.289 s
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 1)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[6] at sortByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 4.6 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:52498 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, ANY, 5142 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, ANY, 5142 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 8 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 8 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2411 bytes result sent to driver
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2394 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 79 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 78 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (sortByKey at SparkJavaRDD.java:45) finished in 0.083 s
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: sortByKey at SparkJavaRDD.java:45, took 0.587983 s
2016-10-27 15:14:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:46
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 4 (reduceByKey at SparkJavaRDD.java:45)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (foreach at SparkJavaRDD.java:46) with 2 output partitions
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (foreach at SparkJavaRDD.java:46)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 3)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 3)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 3 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 4.3 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:52498 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 3 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:45)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 4)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 3.0 (TID 5)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 3.0 (TID 5). 1882 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 3.0 (TID 5) in 40 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4). 1969 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4) in 46 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 3 (reduceByKey at SparkJavaRDD.java:45) finished in 0.049 s
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 4)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:52498 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 4 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 1553 bytes result sent to driver
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 1640 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 43 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 43 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (foreach at SparkJavaRDD.java:46) finished in 0.044 s
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: foreach at SparkJavaRDD.java:46, took 0.128913 s
2016-10-27 15:14:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:48
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (sortByKey at SparkJavaRDD.java:48) with 2 output partitions
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 7 (sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 6)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 7 (MapPartitionsRDD[10] at sortByKey at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:52498 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[10] at sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 8, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 7.0 (TID 9, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 7.0 (TID 9)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 8)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 7.0 (TID 9). 2255 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 7.0 (TID 9) in 16 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 8). 2235 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 8) in 20 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 7 (sortByKey at SparkJavaRDD.java:48) finished in 0.021 s
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: sortByKey at SparkJavaRDD.java:48, took 0.035280 s
2016-10-27 15:14:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:49
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (mapToPair at SparkJavaRDD.java:48)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (foreach at SparkJavaRDD.java:49) with 2 output partitions
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 11 (foreach at SparkJavaRDD.java:49)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 10)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 10)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 10 (MapPartitionsRDD[8] at mapToPair at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:52498 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[8] at mapToPair at SparkJavaRDD.java:48)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 10.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 10.0 (TID 11, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 10.0 (TID 11)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 10.0 (TID 10)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 10). 1882 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 10) in 19 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 10.0 (TID 11). 1882 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 10.0 (TID 11) in 23 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 10 (mapToPair at SparkJavaRDD.java:48) finished in 0.026 s
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 11)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 11 (ShuffledRDD[11] at sortByKey at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:52498 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 11 (ShuffledRDD[11] at sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 11.0 (TID 13, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 11.0 (TID 13)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 12)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13). 1553 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13) in 17 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12). 1553 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12) in 21 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 11 (foreach at SparkJavaRDD.java:49) finished in 0.022 s
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: foreach at SparkJavaRDD.java:49, took 0.069064 s
2016-10-27 15:14:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:56
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 12 (distinct at SparkJavaRDD.java:54)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (sortByKey at SparkJavaRDD.java:56) with 2 output partitions
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 13 (sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 12)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 12)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 12 (MapPartitionsRDD[12] at distinct at SparkJavaRDD.java:54), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.8 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:52498 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[12] at distinct at SparkJavaRDD.java:54)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 12.0 (TID 15, localhost, partition 1, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 14)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 12.0 (TID 15)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_1 locally
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15). 1490 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15) in 26 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14). 1490 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14) in 31 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 12 (distinct at SparkJavaRDD.java:54) finished in 0.031 s
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 13)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 13 (MapPartitionsRDD[17] at sortByKey at SparkJavaRDD.java:56), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.7 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:52498 (size: 2.7 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[17] at sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 13.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 13.0 (TID 16, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 13.0 (TID 17, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 13.0 (TID 17)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 13.0 (TID 16)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 16). 2324 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 16) in 17 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 13.0 (TID 17). 2312 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 13.0 (TID 17) in 21 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 13 (sortByKey at SparkJavaRDD.java:56) finished in 0.023 s
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: sortByKey at SparkJavaRDD.java:56, took 0.083184 s
2016-10-27 15:14:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:56
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 3 is 159 bytes
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 15 (mapToPair at SparkJavaRDD.java:54)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 5 (foreach at SparkJavaRDD.java:56) with 2 output partitions
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 16 (foreach at SparkJavaRDD.java:56)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 15)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 15)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 15 (MapPartitionsRDD[15] at mapToPair at SparkJavaRDD.java:54), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:52498 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[15] at mapToPair at SparkJavaRDD.java:54)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 15.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 15.0 (TID 18, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 15.0 (TID 19, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 15.0 (TID 18)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 15.0 (TID 19)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 18). 1882 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 18) in 16 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 19). 1882 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 19) in 15 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 15 (mapToPair at SparkJavaRDD.java:54) finished in 0.017 s
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 16)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 16 (ShuffledRDD[18] at sortByKey at SparkJavaRDD.java:56), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:52498 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 16 (ShuffledRDD[18] at sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 16.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 16.0 (TID 20, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 16.0 (TID 21, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 16.0 (TID 21)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 16.0 (TID 20)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 16.0 (TID 20). 1553 bytes result sent to driver
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 16.0 (TID 21). 1553 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 16.0 (TID 20) in 16 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 16.0 (TID 21) in 14 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 16 (foreach at SparkJavaRDD.java:56) finished in 0.014 s
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 5 finished: foreach at SparkJavaRDD.java:56, took 0.068684 s
2016-10-27 15:14:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:60
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 19 (mapToPair at SparkJavaRDD.java:58)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 6 (sortByKey at SparkJavaRDD.java:60) with 2 output partitions
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 18 (sortByKey at SparkJavaRDD.java:60)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 17)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 17)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 17 (MapPartitionsRDD[19] at mapToPair at SparkJavaRDD.java:58), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:52498 (size: 3.2 KB, free: 912.2 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[19] at mapToPair at SparkJavaRDD.java:58)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 17.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 17.0 (TID 22, localhost, partition 0, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 17.0 (TID 23, localhost, partition 1, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 17.0 (TID 22)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 17.0 (TID 23)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_1 locally
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 17.0 (TID 22). 1563 bytes result sent to driver
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 17.0 (TID 23). 1563 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 17.0 (TID 22) in 29 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 17.0 (TID 23) in 29 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 17 (mapToPair at SparkJavaRDD.java:58) finished in 0.030 s
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 18)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 18 (MapPartitionsRDD[22] at sortByKey at SparkJavaRDD.java:60), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_13_piece0 in memory on 172.16.106.190:52498 (size: 2.6 KB, free: 912.2 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 13 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[22] at sortByKey at SparkJavaRDD.java:60)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 18.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 18.0 (TID 24, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 18.0 (TID 25, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 18.0 (TID 24)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 18.0 (TID 25)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_1_piece0 on 172.16.106.190:52498 in memory (size: 3.2 KB, free: 912.2 MB)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:52498 in memory (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 2 ms
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:52498 in memory (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 18.0 (TID 24). 1855 bytes result sent to driver
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:52498 in memory (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 18.0 (TID 24) in 12 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:52498 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 18.0 (TID 25). 1865 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 18.0 (TID 25) in 16 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 18 (sortByKey at SparkJavaRDD.java:60) finished in 0.018 s
2016-10-27 15:14:21 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 2
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 6 finished: sortByKey at SparkJavaRDD.java:60, took 0.083611 s
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:52498 in memory (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:52498 in memory (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_8_piece0 on 172.16.106.190:52498 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_9_piece0 on 172.16.106.190:52498 in memory (size: 2.7 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 4
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_10_piece0 on 172.16.106.190:52498 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_11_piece0 on 172.16.106.190:52498 in memory (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:61
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 5 is 159 bytes
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 20 (reduceByKey at SparkJavaRDD.java:60)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 7 (foreach at SparkJavaRDD.java:61) with 2 output partitions
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 21 (foreach at SparkJavaRDD.java:61)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 20)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 20)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 20 (ShuffledRDD[20] at reduceByKey at SparkJavaRDD.java:60), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14 stored as values in memory (estimated size 4.3 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.2 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_14_piece0 in memory on 172.16.106.190:52498 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 14 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 20 (ShuffledRDD[20] at reduceByKey at SparkJavaRDD.java:60)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 20.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 20.0 (TID 26, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 20.0 (TID 27, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 20.0 (TID 26)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 20.0 (TID 27)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 20.0 (TID 27). 1882 bytes result sent to driver
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 20.0 (TID 26). 1882 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 20.0 (TID 27) in 12 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 20.0 (TID 26) in 14 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 20 (reduceByKey at SparkJavaRDD.java:60) finished in 0.014 s
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 21)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 21 (ShuffledRDD[23] at sortByKey at SparkJavaRDD.java:60), which has no missing parents
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_15 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_15_piece0 in memory on 172.16.106.190:52498 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 15 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 21 (ShuffledRDD[23] at sortByKey at SparkJavaRDD.java:60)
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 21.0 with 2 tasks
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 21.0 (TID 28, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 21.0 (TID 29, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 21.0 (TID 28)
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 21.0 (TID 29)
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:14:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 21.0 (TID 29). 1553 bytes result sent to driver
2016-10-27 15:14:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 21.0 (TID 28). 1553 bytes result sent to driver
2016-10-27 15:14:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 21.0 (TID 29) in 7 ms on localhost (1/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 21.0 (TID 28) in 9 ms on localhost (2/2)
2016-10-27 15:14:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 21.0, whose tasks have all completed, from pool 
2016-10-27 15:14:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 21 (foreach at SparkJavaRDD.java:61) finished in 0.009 s
2016-10-27 15:14:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 7 finished: foreach at SparkJavaRDD.java:61, took 0.045561 s
2016-10-27 15:14:21 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:14:21 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-10-27 15:14:21 INFO  [dispatcher-event-loop-0] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-10-27 15:14:22 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-10-27 15:14:22 INFO  [main] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-10-27 15:14:22 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-10-27 15:14:22 INFO  [dispatcher-event-loop-0] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-10-27 15:14:22 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-10-27 15:14:22 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-10-27 15:14:22 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-37cd764d-4597-4c33-81f2-42cc9e0f463a
2016-10-27 15:18:10 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-10-27 15:18:11 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-10-27 15:18:11 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 52523.
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-10-27 15:18:11 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-809d512e-d773-46d8-8d3f-6e61d9e34b92
2016-10-27 15:18:11 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-10-27 15:18:11 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-10-27 15:18:11 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1778ms
2016-10-27 15:18:11 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-10-27 15:18:11 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@4686634{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:18:11 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @1908ms
2016-10-27 15:18:11 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-10-27 15:18:11 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-10-27 15:18:12 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-10-27 15:18:12 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52524.
2016-10-27 15:18:12 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:52524
2016-10-27 15:18:12 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 52524)
2016-10-27 15:18:12 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:52524 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 52524)
2016-10-27 15:18:12 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 52524)
2016-10-27 15:18:12 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-10-27 15:18:12 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-10-27 15:18:12 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:52524 (size: 10.2 KB, free: 912.3 MB)
2016-10-27 15:18:12 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkJavaRDD.java:25
2016-10-27 15:18:12 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-10-27 15:18:13 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:45
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 3 (mapToPair at SparkJavaRDD.java:42)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (sortByKey at SparkJavaRDD.java:45) with 2 output partitions
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 0)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 0)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:42), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:52524 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:42)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_0 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_1 stored as values in memory (estimated size 4.9 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_0 in memory on 172.16.106.190:52524 (size: 5.7 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_1 in memory on 172.16.106.190:52524 (size: 4.9 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 2262 bytes result sent to driver
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 2262 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 200 ms on localhost (1/2)
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 232 ms on localhost (2/2)
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 0 (mapToPair at SparkJavaRDD.java:42) finished in 0.247 s
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 1)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[6] at sortByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 4.6 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:52524 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, ANY, 5142 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, ANY, 5142 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 5 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2394 bytes result sent to driver
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2411 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 77 ms on localhost (1/2)
2016-10-27 15:18:13 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 81 ms on localhost (2/2)
2016-10-27 15:18:13 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (sortByKey at SparkJavaRDD.java:45) finished in 0.082 s
2016-10-27 15:18:13 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: sortByKey at SparkJavaRDD.java:45, took 0.523874 s
2016-10-27 15:18:13 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:46
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 4 (reduceByKey at SparkJavaRDD.java:45)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (foreach at SparkJavaRDD.java:46) with 2 output partitions
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (foreach at SparkJavaRDD.java:46)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 3)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 3)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 3 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 4.3 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.2 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:52524 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 3 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:45)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 3.0 (TID 5)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 4)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 3.0 (TID 5). 1882 bytes result sent to driver
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4). 1882 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 3.0 (TID 5) in 43 ms on localhost (1/2)
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4) in 45 ms on localhost (2/2)
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 3 (reduceByKey at SparkJavaRDD.java:45) finished in 0.046 s
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 4)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:45), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:52524 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 4 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:45)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 1640 bytes result sent to driver
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 1553 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 48 ms on localhost (1/2)
2016-10-27 15:18:13 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 48 ms on localhost (2/2)
2016-10-27 15:18:13 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (foreach at SparkJavaRDD.java:46) finished in 0.049 s
2016-10-27 15:18:13 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: foreach at SparkJavaRDD.java:46, took 0.130261 s
2016-10-27 15:18:13 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:48
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (sortByKey at SparkJavaRDD.java:48) with 2 output partitions
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 7 (sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 6)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 7 (MapPartitionsRDD[10] at sortByKey at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:52524 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[10] at sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 8, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 7.0 (TID 9, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 7.0 (TID 9)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 8)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 7.0 (TID 9). 2255 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 7.0 (TID 9) in 26 ms on localhost (1/2)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 8). 2235 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 8) in 28 ms on localhost (2/2)
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 7 (sortByKey at SparkJavaRDD.java:48) finished in 0.029 s
2016-10-27 15:18:13 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: sortByKey at SparkJavaRDD.java:48, took 0.043333 s
2016-10-27 15:18:13 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:49
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (mapToPair at SparkJavaRDD.java:48)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (foreach at SparkJavaRDD.java:49) with 2 output partitions
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 11 (foreach at SparkJavaRDD.java:49)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 10)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 10)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 10 (MapPartitionsRDD[8] at mapToPair at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:52524 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[8] at mapToPair at SparkJavaRDD.java:48)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 10.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 10.0 (TID 10, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 10.0 (TID 11, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 10.0 (TID 11)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 10.0 (TID 10)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 10.0 (TID 11). 1882 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 10.0 (TID 11) in 31 ms on localhost (1/2)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 10). 1882 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 10) in 36 ms on localhost (2/2)
2016-10-27 15:18:13 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 10 (mapToPair at SparkJavaRDD.java:48) finished in 0.038 s
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 11)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 11 (ShuffledRDD[11] at sortByKey at SparkJavaRDD.java:48), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:52524 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 11 (ShuffledRDD[11] at sortByKey at SparkJavaRDD.java:48)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 11.0 (TID 13, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 11.0 (TID 13)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 12)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12). 1553 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12) in 22 ms on localhost (1/2)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13). 1553 bytes result sent to driver
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13) in 23 ms on localhost (2/2)
2016-10-27 15:18:13 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 11 (foreach at SparkJavaRDD.java:49) finished in 0.026 s
2016-10-27 15:18:13 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: foreach at SparkJavaRDD.java:49, took 0.089353 s
2016-10-27 15:18:13 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:56
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 12 (distinct at SparkJavaRDD.java:54)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (sortByKey at SparkJavaRDD.java:56) with 2 output partitions
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 13 (sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 12)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 12)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 12 (MapPartitionsRDD[12] at distinct at SparkJavaRDD.java:54), which has no missing parents
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.8 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:52524 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[12] at distinct at SparkJavaRDD.java:54)
2016-10-27 15:18:13 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 2 tasks
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 14, localhost, partition 0, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:18:13 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 12.0 (TID 15, localhost, partition 1, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 12.0 (TID 15)
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 14)
2016-10-27 15:18:13 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_1 locally
2016-10-27 15:18:13 INFO  [Executor task launch worker-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15). 1490 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15) in 30 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14). 1490 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14) in 34 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 12 (distinct at SparkJavaRDD.java:54) finished in 0.035 s
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 13)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 13 (MapPartitionsRDD[17] at sortByKey at SparkJavaRDD.java:56), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.7 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:52524 (size: 2.7 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[17] at sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 13.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 13.0 (TID 16, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 13.0 (TID 17, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 13.0 (TID 17)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 13.0 (TID 16)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 13.0 (TID 17). 2399 bytes result sent to driver
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 16). 2324 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 13.0 (TID 17) in 18 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 16) in 20 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 13 (sortByKey at SparkJavaRDD.java:56) finished in 0.022 s
2016-10-27 15:18:14 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: sortByKey at SparkJavaRDD.java:56, took 0.085696 s
2016-10-27 15:18:14 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:56
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 3 is 159 bytes
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 15 (mapToPair at SparkJavaRDD.java:54)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 5 (foreach at SparkJavaRDD.java:56) with 2 output partitions
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 16 (foreach at SparkJavaRDD.java:56)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 15)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 15)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 15 (MapPartitionsRDD[15] at mapToPair at SparkJavaRDD.java:54), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:52524 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[15] at mapToPair at SparkJavaRDD.java:54)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 15.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 15.0 (TID 18, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 15.0 (TID 19, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 15.0 (TID 18)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 15.0 (TID 19)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 19). 1882 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 19) in 18 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 18). 1882 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 18) in 22 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 15 (mapToPair at SparkJavaRDD.java:54) finished in 0.024 s
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 16)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 16 (ShuffledRDD[18] at sortByKey at SparkJavaRDD.java:56), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:52524 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 16 (ShuffledRDD[18] at sortByKey at SparkJavaRDD.java:56)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 16.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 16.0 (TID 20, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 16.0 (TID 21, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 16.0 (TID 21)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 16.0 (TID 20)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 16.0 (TID 20). 1553 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 16.0 (TID 20) in 14 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_1_piece0 on 172.16.106.190:52524 in memory (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 16.0 (TID 21). 1553 bytes result sent to driver
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:52524 in memory (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 16.0 (TID 21) in 19 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 16.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 16 (foreach at SparkJavaRDD.java:56) finished in 0.021 s
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:52524 in memory (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 5 finished: foreach at SparkJavaRDD.java:56, took 0.082113 s
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:52524 in memory (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:52524 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 2
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:52524 in memory (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:52524 in memory (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_8_piece0 on 172.16.106.190:52524 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_9_piece0 on 172.16.106.190:52524 in memory (size: 2.7 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: saveAsTextFile at SparkJavaRDD.java:57
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 3 is 159 bytes
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 6 (saveAsTextFile at SparkJavaRDD.java:57) with 2 output partitions
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 18 (saveAsTextFile at SparkJavaRDD.java:57)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 17)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 18 (MapPartitionsRDD[19] at saveAsTextFile at SparkJavaRDD.java:57), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 50.5 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 18.4 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:52524 (size: 18.4 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[19] at saveAsTextFile at SparkJavaRDD.java:57)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 18.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 18.0 (TID 22, localhost, partition 0, ANY, 5148 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 18.0 (TID 23, localhost, partition 1, ANY, 5148 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 18.0 (TID 23)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 18.0 (TID 22)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.h.m.l.o.FileOutputCommitter [FileOutputCommitter.java:439] : Saved output of task 'attempt_201610271518_0018_m_000000_22' to file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/word-lengthcount.txt/_temporary/0/task_201610271518_0018_m_000000
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.h.m.l.o.FileOutputCommitter [FileOutputCommitter.java:439] : Saved output of task 'attempt_201610271518_0018_m_000001_23' to file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/word-lengthcount.txt/_temporary/0/task_201610271518_0018_m_000001
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.mapred.SparkHadoopMapRedUtil [Logging.scala:54] : attempt_201610271518_0018_m_000000_22: Committed
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.mapred.SparkHadoopMapRedUtil [Logging.scala:54] : attempt_201610271518_0018_m_000001_23: Committed
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 18.0 (TID 23). 1553 bytes result sent to driver
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 18.0 (TID 22). 1553 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 18.0 (TID 23) in 100 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 18.0 (TID 22) in 102 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 18 (saveAsTextFile at SparkJavaRDD.java:57) finished in 0.102 s
2016-10-27 15:18:14 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 6 finished: saveAsTextFile at SparkJavaRDD.java:57, took 0.123777 s
2016-10-27 15:18:14 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkJavaRDD.java:61
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 20 (mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 7 (sortByKey at SparkJavaRDD.java:61) with 2 output partitions
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 20 (sortByKey at SparkJavaRDD.java:61)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 19)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 19)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 19 (MapPartitionsRDD[20] at mapToPair at SparkJavaRDD.java:59), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_13_piece0 in memory on 172.16.106.190:52524 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 13 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[20] at mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 19.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 19.0 (TID 24, localhost, partition 0, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 19.0 (TID 25, localhost, partition 1, PROCESS_LOCAL, 5381 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 19.0 (TID 25)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 19.0 (TID 24)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_1 locally
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 19.0 (TID 25). 1490 bytes result sent to driver
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 19.0 (TID 24). 1490 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 19.0 (TID 25) in 15 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 19.0 (TID 24) in 18 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 19.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 19 (mapToPair at SparkJavaRDD.java:59) finished in 0.019 s
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 20)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 20 (MapPartitionsRDD[23] at sortByKey at SparkJavaRDD.java:61), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_14_piece0 in memory on 172.16.106.190:52524 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 14 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 20 (MapPartitionsRDD[23] at sortByKey at SparkJavaRDD.java:61)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 20.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 20.0 (TID 26, localhost, partition 0, ANY, 5143 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 20.0 (TID 27, localhost, partition 1, ANY, 5143 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 20.0 (TID 26)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 20.0 (TID 27)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 20.0 (TID 26). 1855 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 20.0 (TID 26) in 11 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 20.0 (TID 27). 1865 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 20.0 (TID 27) in 16 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 20 (sortByKey at SparkJavaRDD.java:61) finished in 0.019 s
2016-10-27 15:18:14 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 7 finished: sortByKey at SparkJavaRDD.java:61, took 0.057581 s
2016-10-27 15:18:14 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:62
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 5 is 159 bytes
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 21 (reduceByKey at SparkJavaRDD.java:61)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 8 (foreach at SparkJavaRDD.java:62) with 2 output partitions
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 23 (foreach at SparkJavaRDD.java:62)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 22)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 22)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 22 (ShuffledRDD[21] at reduceByKey at SparkJavaRDD.java:61), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_15 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_15_piece0 in memory on 172.16.106.190:52524 (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 15 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 22 (ShuffledRDD[21] at reduceByKey at SparkJavaRDD.java:61)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 22.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 22.0 (TID 28, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 22.0 (TID 29, localhost, partition 1, ANY, 5130 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 22.0 (TID 28)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 22.0 (TID 29)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 22.0 (TID 28). 1969 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 22.0 (TID 28) in 11 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 22.0 (TID 29). 1882 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 22.0 (TID 29) in 12 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 22 (reduceByKey at SparkJavaRDD.java:61) finished in 0.015 s
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 23)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 23 (ShuffledRDD[24] at sortByKey at SparkJavaRDD.java:61), which has no missing parents
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_16 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_16_piece0 in memory on 172.16.106.190:52524 (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 16 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 23 (ShuffledRDD[24] at sortByKey at SparkJavaRDD.java:61)
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 23.0 with 2 tasks
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 23.0 (TID 30, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 23.0 (TID 31, localhost, partition 1, ANY, 5141 bytes)
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 23.0 (TID 31)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 23.0 (TID 30)
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:18:14 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 23.0 (TID 30). 1553 bytes result sent to driver
2016-10-27 15:18:14 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 23.0 (TID 31). 1553 bytes result sent to driver
2016-10-27 15:18:14 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 23.0 (TID 30) in 8 ms on localhost (1/2)
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 23.0 (TID 31) in 8 ms on localhost (2/2)
2016-10-27 15:18:14 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-10-27 15:18:14 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 23 (foreach at SparkJavaRDD.java:62) finished in 0.009 s
2016-10-27 15:18:14 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 8 finished: foreach at SparkJavaRDD.java:62, took 0.043774 s
2016-10-27 15:18:14 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@4686634{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:18:14 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-10-27 15:18:14 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-10-27 15:18:14 INFO  [main] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-10-27 15:18:14 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-10-27 15:18:14 INFO  [dispatcher-event-loop-3] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-10-27 15:18:14 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-10-27 15:18:14 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-10-27 15:18:14 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-69c223c7-7f77-4d7e-85f7-8c4dde3f9455
2016-10-27 15:20:17 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-10-27 15:20:17 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-27 15:20:17 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-10-27 15:20:17 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-10-27 15:20:17 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-10-27 15:20:17 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-10-27 15:20:17 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-10-27 15:20:18 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 52539.
2016-10-27 15:20:18 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-10-27 15:20:18 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-10-27 15:20:18 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-0ec04910-4ede-488d-86d7-c3f2a08789cc
2016-10-27 15:20:18 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-10-27 15:20:18 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-10-27 15:20:18 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1725ms
2016-10-27 15:20:18 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-10-27 15:20:18 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:20:18 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @1842ms
2016-10-27 15:20:18 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-10-27 15:20:18 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-10-27 15:20:18 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-10-27 15:20:18 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52540.
2016-10-27 15:20:18 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:52540
2016-10-27 15:20:18 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 52540)
2016-10-27 15:20:18 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:52540 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 52540)
2016-10-27 15:20:18 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 52540)
2016-10-27 15:20:19 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-10-27 15:20:19 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-10-27 15:20:19 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:52540 (size: 10.2 KB, free: 912.3 MB)
2016-10-27 15:20:19 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkJavaRDD.java:26
2016-10-27 15:20:19 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-10-27 15:20:19 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:47
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 3 (mapToPair at SparkJavaRDD.java:43)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 4 (reduceByKey at SparkJavaRDD.java:46)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (foreach at SparkJavaRDD.java:47) with 1 output partitions
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (foreach at SparkJavaRDD.java:47)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:43), which has no missing parents
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
2016-10-27 15:20:19 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:52540 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:43)
2016-10-27 15:20:19 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 1 tasks
2016-10-27 15:20:19 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5378 bytes)
2016-10-27 15:20:19 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-10-27 15:20:19 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+3359
2016-10-27 15:20:19 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:20:19 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-10-27 15:20:19 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-10-27 15:20:19 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-10-27 15:20:19 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_0 stored as values in memory (estimated size 10.7 KB, free 912.2 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_0 in memory on 172.16.106.190:52540 (size: 10.7 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 2261 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 315 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 0 (mapToPair at SparkJavaRDD.java:43) finished in 0.338 s
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ShuffleMapStage 1, ResultStage 2)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:46), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 4.3 KB, free 912.2 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.2 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:52540 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 1 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:46)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5129 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 1)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 5 ms
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1). 1881 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1) in 90 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (reduceByKey at SparkJavaRDD.java:46) finished in 0.091 s
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (ShuffledRDD[5] at sortByKey at SparkJavaRDD.java:46), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 912.2 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 912.2 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:52540 (size: 2.3 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[5] at sortByKey at SparkJavaRDD.java:46)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5140 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 2)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2). 1640 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (foreach at SparkJavaRDD.java:47) finished in 0.063 s
2016-10-27 15:20:20 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: foreach at SparkJavaRDD.java:47, took 0.760093 s
2016-10-27 15:20:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:50
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 147 bytes
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 147 bytes
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (mapToPair at SparkJavaRDD.java:49)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (foreach at SparkJavaRDD.java:50) with 1 output partitions
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 6 (foreach at SparkJavaRDD.java:50)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 5)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 5)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 5 (MapPartitionsRDD[6] at mapToPair at SparkJavaRDD.java:49), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.4 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:52540 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[6] at mapToPair at SparkJavaRDD.java:49)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 3, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 3)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 3). 1881 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 3) in 46 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 5 (mapToPair at SparkJavaRDD.java:49) finished in 0.046 s
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 6)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 6 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:49), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:52540 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 6 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:49)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 6.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 6.0 (TID 4, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 6.0 (TID 4)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 4). 1553 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 4) in 33 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 6 (foreach at SparkJavaRDD.java:50) finished in 0.035 s
2016-10-27 15:20:20 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: foreach at SparkJavaRDD.java:50, took 0.112260 s
2016-10-27 15:20:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:57
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (distinct at SparkJavaRDD.java:55)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 11 (mapToPair at SparkJavaRDD.java:55)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (foreach at SparkJavaRDD.java:57) with 1 output partitions
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 9 (foreach at SparkJavaRDD.java:57)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 8)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 8)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 7 (MapPartitionsRDD[8] at distinct at SparkJavaRDD.java:55), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 4.8 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:52540 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[8] at distinct at SparkJavaRDD.java:55)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5379 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 5)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 5). 1489 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 5) in 46 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 7 (distinct at SparkJavaRDD.java:55) finished in 0.052 s
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 9, ShuffleMapStage 8)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 8 (MapPartitionsRDD[11] at mapToPair at SparkJavaRDD.java:55), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:52540 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[11] at mapToPair at SparkJavaRDD.java:55)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 6)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 6). 1881 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 6) in 29 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 8 (mapToPair at SparkJavaRDD.java:55) finished in 0.032 s
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 9)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 9 (ShuffledRDD[12] at sortByKey at SparkJavaRDD.java:57), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:52540 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[12] at sortByKey at SparkJavaRDD.java:57)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 9.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 9.0 (TID 7, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 9.0 (TID 7)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 9.0 (TID 7). 1553 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 9.0 (TID 7) in 23 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 9 (foreach at SparkJavaRDD.java:57) finished in 0.025 s
2016-10-27 15:20:20 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: foreach at SparkJavaRDD.java:57, took 0.148237 s
2016-10-27 15:20:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: saveAsTextFile at SparkJavaRDD.java:58
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 4 is 147 bytes
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (saveAsTextFile at SparkJavaRDD.java:58) with 1 output partitions
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 11 (saveAsTextFile at SparkJavaRDD.java:58)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 10)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 11 (MapPartitionsRDD[13] at saveAsTextFile at SparkJavaRDD.java:58), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 50.5 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.4 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:52540 (size: 18.4 KB, free: 912.2 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[13] at saveAsTextFile at SparkJavaRDD.java:58)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 8, localhost, partition 0, ANY, 5148 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 8)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.h.m.l.o.FileOutputCommitter [FileOutputCommitter.java:439] : Saved output of task 'attempt_201610271520_0011_m_000000_8' to file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/word-length-count.txt/_temporary/0/task_201610271520_0011_m_000000
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.a.s.mapred.SparkHadoopMapRedUtil [Logging.scala:54] : attempt_201610271520_0011_m_000000_8: Committed
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 8). 1553 bytes result sent to driver
2016-10-27 15:20:20 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 8) in 87 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 11 (saveAsTextFile at SparkJavaRDD.java:58) finished in 0.087 s
2016-10-27 15:20:20 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: saveAsTextFile at SparkJavaRDD.java:58, took 0.116047 s
2016-10-27 15:20:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:63
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 14 (mapToPair at SparkJavaRDD.java:60)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 15 (reduceByKey at SparkJavaRDD.java:62)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (foreach at SparkJavaRDD.java:63) with 1 output partitions
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 14 (foreach at SparkJavaRDD.java:63)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 13)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 13)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 12 (MapPartitionsRDD[14] at mapToPair at SparkJavaRDD.java:60), which has no missing parents
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 5.7 KB, free 912.0 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.0 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:52540 (size: 3.2 KB, free: 912.2 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[14] at mapToPair at SparkJavaRDD.java:60)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 1 tasks
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5379 bytes)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 9)
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:52540 in memory (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:52540 in memory (size: 2.3 KB, free: 912.2 MB)
2016-10-27 15:20:20 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 2
2016-10-27 15:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 9). 1489 bytes result sent to driver
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:52540 in memory (size: 2.6 KB, free: 912.2 MB)
2016-10-27 15:20:20 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 9) in 24 ms on localhost (1/1)
2016-10-27 15:20:20 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:52540 in memory (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 12 (mapToPair at SparkJavaRDD.java:60) finished in 0.024 s
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ShuffleMapStage 13, ResultStage 14)
2016-10-27 15:20:20 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 3
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 13 (ShuffledRDD[15] at reduceByKey at SparkJavaRDD.java:62), which has no missing parents
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:52540 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:52540 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-10-27 15:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_8_piece0 on 172.16.106.190:52540 in memory (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-10-27 15:20:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:52540 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:20:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_9_piece0 on 172.16.106.190:52540 in memory (size: 18.4 KB, free: 912.3 MB)
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 13 (ShuffledRDD[15] at reduceByKey at SparkJavaRDD.java:62)
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 13.0 with 1 tasks
2016-10-27 15:20:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 13.0 (TID 10)
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 10). 1881 bytes result sent to driver
2016-10-27 15:20:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 10) in 11 ms on localhost (1/1)
2016-10-27 15:20:21 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 13 (reduceByKey at SparkJavaRDD.java:62) finished in 0.012 s
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 14)
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 14 (ShuffledRDD[16] at sortByKey at SparkJavaRDD.java:62), which has no missing parents
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:20:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:52540 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 14 (ShuffledRDD[16] at sortByKey at SparkJavaRDD.java:62)
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 14.0 with 1 tasks
2016-10-27 15:20:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 14.0 (TID 11, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 14.0 (TID 11)
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:20:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 14.0 (TID 11). 1553 bytes result sent to driver
2016-10-27 15:20:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 14.0 (TID 11) in 9 ms on localhost (1/1)
2016-10-27 15:20:21 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-10-27 15:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 14 (foreach at SparkJavaRDD.java:63) finished in 0.011 s
2016-10-27 15:20:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: foreach at SparkJavaRDD.java:63, took 0.095737 s
2016-10-27 15:20:21 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:20:21 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-10-27 15:20:21 INFO  [dispatcher-event-loop-2] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-10-27 15:20:21 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-10-27 15:20:21 INFO  [main] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-10-27 15:20:21 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-10-27 15:20:21 INFO  [dispatcher-event-loop-2] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-10-27 15:20:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-10-27 15:20:21 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-10-27 15:20:21 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-aa7636dc-9f4c-4873-b444-048215236084
2016-10-27 15:21:24 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-10-27 15:21:24 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-27 15:21:24 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-10-27 15:21:24 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-10-27 15:21:24 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-10-27 15:21:24 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-10-27 15:21:24 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-10-27 15:21:25 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 52550.
2016-10-27 15:21:25 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-10-27 15:21:25 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-10-27 15:21:25 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-485bb4d5-e359-45a7-9414-beecc4a540e1
2016-10-27 15:21:25 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-10-27 15:21:25 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-10-27 15:21:25 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1686ms
2016-10-27 15:21:25 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-10-27 15:21:25 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:21:25 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @1813ms
2016-10-27 15:21:25 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-10-27 15:21:25 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-10-27 15:21:25 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-10-27 15:21:25 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52551.
2016-10-27 15:21:25 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:52551
2016-10-27 15:21:25 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 52551)
2016-10-27 15:21:25 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:52551 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 52551)
2016-10-27 15:21:25 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 52551)
2016-10-27 15:21:26 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-10-27 15:21:26 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-10-27 15:21:26 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:52551 (size: 10.2 KB, free: 912.3 MB)
2016-10-27 15:21:26 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkJavaRDD.java:26
2016-10-27 15:21:26 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-10-27 15:21:26 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:47
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 3 (mapToPair at SparkJavaRDD.java:43)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 4 (reduceByKey at SparkJavaRDD.java:46)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (foreach at SparkJavaRDD.java:47) with 1 output partitions
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (foreach at SparkJavaRDD.java:47)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:43), which has no missing parents
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
2016-10-27 15:21:26 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:52551 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:43)
2016-10-27 15:21:26 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 1 tasks
2016-10-27 15:21:26 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5378 bytes)
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+3359
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-10-27 15:21:26 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_1_0 stored as values in memory (estimated size 10.7 KB, free 912.2 MB)
2016-10-27 15:21:26 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_1_0 in memory on 172.16.106.190:52551 (size: 10.7 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 2261 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 268 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 0 (mapToPair at SparkJavaRDD.java:43) finished in 0.287 s
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ShuffleMapStage 1, ResultStage 2)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:46), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 4.3 KB, free 912.2 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.2 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:52551 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 1 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:46)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5129 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 1)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1). 1881 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1) in 81 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (reduceByKey at SparkJavaRDD.java:46) finished in 0.083 s
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (ShuffledRDD[5] at sortByKey at SparkJavaRDD.java:46), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 912.2 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 912.2 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:52551 (size: 2.3 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[5] at sortByKey at SparkJavaRDD.java:46)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5140 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 2)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2). 1640 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2) in 56 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (foreach at SparkJavaRDD.java:47) finished in 0.057 s
2016-10-27 15:21:27 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: foreach at SparkJavaRDD.java:47, took 0.720244 s
2016-10-27 15:21:27 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:50
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 147 bytes
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 147 bytes
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (mapToPair at SparkJavaRDD.java:49)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (foreach at SparkJavaRDD.java:50) with 1 output partitions
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 6 (foreach at SparkJavaRDD.java:50)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 5)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 5)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 5 (MapPartitionsRDD[6] at mapToPair at SparkJavaRDD.java:49), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.4 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:52551 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[6] at mapToPair at SparkJavaRDD.java:49)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 3, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 3)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 3). 1881 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 3) in 32 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 5 (mapToPair at SparkJavaRDD.java:49) finished in 0.033 s
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 6)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 6 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:49), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:52551 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 6 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:49)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 6.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 6.0 (TID 4, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 6.0 (TID 4)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 4). 1553 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 4) in 26 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 6 (foreach at SparkJavaRDD.java:50) finished in 0.027 s
2016-10-27 15:21:27 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: foreach at SparkJavaRDD.java:50, took 0.091839 s
2016-10-27 15:21:27 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:57
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (distinct at SparkJavaRDD.java:55)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 11 (mapToPair at SparkJavaRDD.java:55)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (foreach at SparkJavaRDD.java:57) with 1 output partitions
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 9 (foreach at SparkJavaRDD.java:57)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 8)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 8)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 7 (MapPartitionsRDD[8] at distinct at SparkJavaRDD.java:55), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 4.8 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:52551 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[8] at distinct at SparkJavaRDD.java:55)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5379 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 5)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 5). 1489 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 5) in 32 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 7 (distinct at SparkJavaRDD.java:55) finished in 0.032 s
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 9, ShuffleMapStage 8)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 8 (MapPartitionsRDD[11] at mapToPair at SparkJavaRDD.java:55), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:52551 (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[11] at mapToPair at SparkJavaRDD.java:55)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 6)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 6). 1881 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 6) in 22 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 8 (mapToPair at SparkJavaRDD.java:55) finished in 0.023 s
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 9)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 9 (ShuffledRDD[12] at sortByKey at SparkJavaRDD.java:57), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:52551 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[12] at sortByKey at SparkJavaRDD.java:57)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 9.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 9.0 (TID 7, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 9.0 (TID 7)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 9.0 (TID 7). 1553 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 9.0 (TID 7) in 23 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 9 (foreach at SparkJavaRDD.java:57) finished in 0.024 s
2016-10-27 15:21:27 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: foreach at SparkJavaRDD.java:57, took 0.112524 s
2016-10-27 15:21:27 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:62
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 13 (mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 14 (reduceByKey at SparkJavaRDD.java:61)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (foreach at SparkJavaRDD.java:62) with 1 output partitions
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 12 (foreach at SparkJavaRDD.java:62)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 11)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 11)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 10 (MapPartitionsRDD[13] at mapToPair at SparkJavaRDD.java:59), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:52551 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[13] at mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 10.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 10.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5379 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 10.0 (TID 8)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 8). 1489 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 8) in 18 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 10 (mapToPair at SparkJavaRDD.java:59) finished in 0.019 s
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12, ShuffleMapStage 11)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 11 (ShuffledRDD[14] at reduceByKey at SparkJavaRDD.java:61), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:52551 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 11 (ShuffledRDD[14] at reduceByKey at SparkJavaRDD.java:61)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 9)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 9). 1881 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 9) in 12 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 11 (reduceByKey at SparkJavaRDD.java:61) finished in 0.013 s
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 12 (ShuffledRDD[15] at sortByKey at SparkJavaRDD.java:61), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:52551 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 12 (ShuffledRDD[15] at sortByKey at SparkJavaRDD.java:61)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 10, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 10)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 10). 1553 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 10) in 8 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 12 (foreach at SparkJavaRDD.java:62) finished in 0.010 s
2016-10-27 15:21:27 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: foreach at SparkJavaRDD.java:62, took 0.086830 s
2016-10-27 15:21:27 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: saveAsTextFile at SparkJavaRDD.java:63
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (saveAsTextFile at SparkJavaRDD.java:63) with 1 output partitions
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 13 (saveAsTextFile at SparkJavaRDD.java:63)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 13 (MapPartitionsRDD[16] at saveAsTextFile at SparkJavaRDD.java:63), which has no missing parents
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 50.7 KB, free 912.0 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 18.5 KB, free 912.0 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:52551 (size: 18.5 KB, free: 912.2 MB)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[16] at saveAsTextFile at SparkJavaRDD.java:63)
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 13.0 with 1 tasks
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 13.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5397 bytes)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 13.0 (TID 11)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:52551 in memory (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_8_piece0 on 172.16.106.190:52551 in memory (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:21:27 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 5
2016-10-27 15:21:27 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 6
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_9_piece0 on 172.16.106.190:52551 in memory (size: 3.2 KB, free: 912.2 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_10_piece0 on 172.16.106.190:52551 in memory (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_11_piece0 on 172.16.106.190:52551 in memory (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:52551 in memory (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:52551 in memory (size: 2.3 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 2
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:52551 in memory (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 3
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:52551 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:52551 in memory (size: 2.8 KB, free: 912.3 MB)
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_1_0 locally
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.h.m.l.o.FileOutputCommitter [FileOutputCommitter.java:439] : Saved output of task 'attempt_201610271521_0013_m_000000_11' to file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/word-length-count.txt/_temporary/0/task_201610271521_0013_m_000000
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] o.a.s.mapred.SparkHadoopMapRedUtil [Logging.scala:54] : attempt_201610271521_0013_m_000000_11: Committed
2016-10-27 15:21:27 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 11). 916 bytes result sent to driver
2016-10-27 15:21:27 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 11) in 98 ms on localhost (1/1)
2016-10-27 15:21:27 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-27 15:21:27 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 13 (saveAsTextFile at SparkJavaRDD.java:63) finished in 0.099 s
2016-10-27 15:21:27 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: saveAsTextFile at SparkJavaRDD.java:63, took 0.145416 s
2016-10-27 15:21:27 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@7c2b6087{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:21:27 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-10-27 15:21:27 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-10-27 15:21:27 INFO  [main] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-10-27 15:21:27 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-10-27 15:21:27 INFO  [dispatcher-event-loop-2] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-10-27 15:21:27 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-10-27 15:21:27 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-10-27 15:21:27 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-9d0f0d3c-d98f-4f5d-8019-613daa3e8a60
2016-10-27 15:24:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-10-27 15:24:20 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-27 15:24:20 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-10-27 15:24:20 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-10-27 15:24:20 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-10-27 15:24:20 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-10-27 15:24:20 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-10-27 15:24:21 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 52565.
2016-10-27 15:24:21 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-10-27 15:24:21 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-10-27 15:24:21 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-4ed990a8-2b61-4a65-a7e4-28eccd1ea7e5
2016-10-27 15:24:21 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-10-27 15:24:21 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-10-27 15:24:21 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1688ms
2016-10-27 15:24:21 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-10-27 15:24:21 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@35688ba1{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:24:21 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @1802ms
2016-10-27 15:24:21 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-10-27 15:24:21 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-10-27 15:24:21 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-10-27 15:24:21 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52566.
2016-10-27 15:24:21 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:52566
2016-10-27 15:24:21 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 52566)
2016-10-27 15:24:21 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:52566 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 52566)
2016-10-27 15:24:21 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 52566)
2016-10-27 15:24:22 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-10-27 15:24:22 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-10-27 15:24:22 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:52566 (size: 10.2 KB, free: 912.3 MB)
2016-10-27 15:24:22 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkJavaRDD.java:26
2016-10-27 15:24:22 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-10-27 15:24:22 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:47
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 3 (mapToPair at SparkJavaRDD.java:43)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 4 (reduceByKey at SparkJavaRDD.java:46)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (foreach at SparkJavaRDD.java:47) with 1 output partitions
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (foreach at SparkJavaRDD.java:47)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:43), which has no missing parents
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 5.7 KB, free 912.2 MB)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
2016-10-27 15:24:22 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:52566 (size: 3.2 KB, free: 912.3 MB)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at mapToPair at SparkJavaRDD.java:43)
2016-10-27 15:24:22 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 1 tasks
2016-10-27 15:24:22 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5378 bytes)
2016-10-27 15:24:22 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-10-27 15:24:22 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+3359
2016-10-27 15:24:22 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-10-27 15:24:22 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-10-27 15:24:22 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-10-27 15:24:22 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-10-27 15:24:22 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_2_0 stored as values in memory (estimated size 27.8 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_2_0 in memory on 172.16.106.190:52566 (size: 27.8 KB, free: 912.3 MB)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 2261 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 306 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 0 (mapToPair at SparkJavaRDD.java:43) finished in 0.327 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ShuffleMapStage 1, ResultStage 2)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:46), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:52566 (size: 2.5 KB, free: 912.3 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 1 (ShuffledRDD[4] at reduceByKey at SparkJavaRDD.java:46)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5129 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 1)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1). 1881 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1) in 74 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (reduceByKey at SparkJavaRDD.java:46) finished in 0.075 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (ShuffledRDD[5] at sortByKey at SparkJavaRDD.java:46), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:52566 (size: 2.3 KB, free: 912.3 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[5] at sortByKey at SparkJavaRDD.java:46)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, ANY, 5140 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 2)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2). 1640 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (foreach at SparkJavaRDD.java:47) finished in 0.033 s
2016-10-27 15:24:23 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: foreach at SparkJavaRDD.java:47, took 0.703570 s
2016-10-27 15:24:23 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:50
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 147 bytes
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 147 bytes
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (mapToPair at SparkJavaRDD.java:49)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (foreach at SparkJavaRDD.java:50) with 1 output partitions
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 6 (foreach at SparkJavaRDD.java:50)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 5)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 5)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 5 (MapPartitionsRDD[6] at mapToPair at SparkJavaRDD.java:49), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.4 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:52566 (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[6] at mapToPair at SparkJavaRDD.java:49)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 3, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 3)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 3). 1881 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 3) in 25 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 5 (mapToPair at SparkJavaRDD.java:49) finished in 0.025 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 6)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 6 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:49), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:52566 (size: 2.4 KB, free: 912.3 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 6 (ShuffledRDD[7] at sortByKey at SparkJavaRDD.java:49)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 6.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 6.0 (TID 4, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 6.0 (TID 4)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 4). 1553 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 4) in 24 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 6 (foreach at SparkJavaRDD.java:50) finished in 0.026 s
2016-10-27 15:24:23 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: foreach at SparkJavaRDD.java:50, took 0.084368 s
2016-10-27 15:24:23 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:57
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (distinct at SparkJavaRDD.java:55)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 11 (mapToPair at SparkJavaRDD.java:55)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (foreach at SparkJavaRDD.java:57) with 1 output partitions
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 9 (foreach at SparkJavaRDD.java:57)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 8)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 8)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 7 (MapPartitionsRDD[8] at distinct at SparkJavaRDD.java:55), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 4.8 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:52566 (size: 2.8 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[8] at distinct at SparkJavaRDD.java:55)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5379 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 5)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_2_0 locally
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 5). 1489 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 5) in 26 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 7 (distinct at SparkJavaRDD.java:55) finished in 0.027 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 9, ShuffleMapStage 8)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 8 (MapPartitionsRDD[11] at mapToPair at SparkJavaRDD.java:55), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:52566 (size: 2.8 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[11] at mapToPair at SparkJavaRDD.java:55)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 6)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 6). 1881 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 6) in 16 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 8 (mapToPair at SparkJavaRDD.java:55) finished in 0.017 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 9)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 9 (ShuffledRDD[12] at sortByKey at SparkJavaRDD.java:57), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:52566 (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[12] at sortByKey at SparkJavaRDD.java:57)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 9.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 9.0 (TID 7, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 9.0 (TID 7)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 9.0 (TID 7). 1553 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 9.0 (TID 7) in 20 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 9 (foreach at SparkJavaRDD.java:57) finished in 0.021 s
2016-10-27 15:24:23 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: foreach at SparkJavaRDD.java:57, took 0.100212 s
2016-10-27 15:24:23 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkJavaRDD.java:63
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 13 (mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 14 (reduceByKey at SparkJavaRDD.java:62)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (foreach at SparkJavaRDD.java:63) with 1 output partitions
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 12 (foreach at SparkJavaRDD.java:63)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 11)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 11)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 10 (MapPartitionsRDD[13] at mapToPair at SparkJavaRDD.java:59), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:52566 (size: 3.2 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[13] at mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 10.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 10.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5379 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 10.0 (TID 8)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_2_0 locally
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 8). 1489 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 10.0 (TID 8) in 13 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 10.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 10 (mapToPair at SparkJavaRDD.java:59) finished in 0.014 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12, ShuffleMapStage 11)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 11 (ShuffledRDD[14] at reduceByKey at SparkJavaRDD.java:62), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:52566 (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 11 (ShuffledRDD[14] at reduceByKey at SparkJavaRDD.java:62)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5130 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 9)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 9). 1968 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 9) in 12 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 11 (reduceByKey at SparkJavaRDD.java:62) finished in 0.013 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 12 (ShuffledRDD[15] at sortByKey at SparkJavaRDD.java:62), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 4.0 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:52566 (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 12 (ShuffledRDD[15] at sortByKey at SparkJavaRDD.java:62)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 10, localhost, partition 0, ANY, 5141 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 10)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 10). 1553 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 10) in 11 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 12 (foreach at SparkJavaRDD.java:63) finished in 0.012 s
2016-10-27 15:24:23 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: foreach at SparkJavaRDD.java:63, took 0.074961 s
2016-10-27 15:24:23 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: saveAsTextFile at SparkJavaRDD.java:64
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 13 (mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 16 (reduceByKey at SparkJavaRDD.java:64)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (saveAsTextFile at SparkJavaRDD.java:64) with 1 output partitions
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 15 (saveAsTextFile at SparkJavaRDD.java:64)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 14)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 14)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 13 (MapPartitionsRDD[13] at mapToPair at SparkJavaRDD.java:59), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:52566 (size: 3.2 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[13] at mapToPair at SparkJavaRDD.java:59)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 13.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 13.0 (TID 11, localhost, partition 0, PROCESS_LOCAL, 5386 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 13.0 (TID 11)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.apache.spark.storage.BlockManager [Logging.scala:54] : Found block rdd_2_0 locally
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_11_piece0 on 172.16.106.190:52566 in memory (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:52566 in memory (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 11). 1489 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 13.0 (TID 11) in 12 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 13 (mapToPair at SparkJavaRDD.java:59) finished in 0.014 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 15, ShuffleMapStage 14)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 14 (ShuffledRDD[16] at reduceByKey at SparkJavaRDD.java:64), which has no missing parents
2016-10-27 15:24:23 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 3
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:52566 in memory (size: 2.8 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:52566 in memory (size: 2.8 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_13_piece0 in memory on 172.16.106.190:52566 (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 13 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 14 (ShuffledRDD[16] at reduceByKey at SparkJavaRDD.java:64)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_8_piece0 on 172.16.106.190:52566 in memory (size: 2.4 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 14.0 with 1 tasks
2016-10-27 15:24:23 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 5
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 14.0 (TID 12, localhost, partition 0, ANY, 5137 bytes)
2016-10-27 15:24:23 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 6
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 14.0 (TID 12)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_9_piece0 on 172.16.106.190:52566 in memory (size: 3.2 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_10_piece0 on 172.16.106.190:52566 in memory (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:52566 in memory (size: 2.5 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:52566 in memory (size: 2.3 KB, free: 912.3 MB)
2016-10-27 15:24:23 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 2
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:52566 in memory (size: 2.6 KB, free: 912.3 MB)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 14.0 (TID 12). 1881 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 14.0 (TID 12) in 12 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 14 (reduceByKey at SparkJavaRDD.java:64) finished in 0.012 s
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 15)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 15 (MapPartitionsRDD[18] at saveAsTextFile at SparkJavaRDD.java:64), which has no missing parents
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14 stored as values in memory (estimated size 49.8 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.0 KB, free 912.1 MB)
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_14_piece0 in memory on 172.16.106.190:52566 (size: 18.0 KB, free: 912.2 MB)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 14 from broadcast at DAGScheduler.scala:1012
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[18] at saveAsTextFile at SparkJavaRDD.java:64)
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 15.0 with 1 tasks
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 15.0 (TID 13, localhost, partition 0, ANY, 5148 bytes)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 15.0 (TID 13)
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.h.m.l.o.FileOutputCommitter [FileOutputCommitter.java:439] : Saved output of task 'attempt_201610271524_0015_m_000000_13' to file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/word-length-count.txt/_temporary/0/task_201610271524_0015_m_000000
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] o.a.s.mapred.SparkHadoopMapRedUtil [Logging.scala:54] : attempt_201610271524_0015_m_000000_13: Committed
2016-10-27 15:24:23 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 13). 1553 bytes result sent to driver
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 13) in 73 ms on localhost (1/1)
2016-10-27 15:24:23 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-10-27 15:24:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 15 (saveAsTextFile at SparkJavaRDD.java:64) finished in 0.074 s
2016-10-27 15:24:23 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: saveAsTextFile at SparkJavaRDD.java:64, took 0.149745 s
2016-10-27 15:24:23 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@35688ba1{HTTP/1.1}{0.0.0.0:4040}
2016-10-27 15:24:23 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-10-27 15:24:23 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-10-27 15:24:23 INFO  [main] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-10-27 15:24:23 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-10-27 15:24:23 INFO  [dispatcher-event-loop-2] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-10-27 15:24:23 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-10-27 15:24:23 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-10-27 15:24:23 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-bc483d0d-e62d-40cd-b191-fd24f75dc912
