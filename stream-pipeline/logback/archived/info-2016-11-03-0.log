2016-11-03 10:53:41 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-11-03 10:53:41 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-11-03 10:53:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-11-03 10:53:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-11-03 10:53:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-11-03 10:53:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-11-03 10:53:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-11-03 10:53:42 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 59951.
2016-11-03 10:53:42 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-11-03 10:53:42 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-11-03 10:53:43 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-0ffc2c86-e787-4b2b-8074-51d336a5e45a
2016-11-03 10:53:43 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-11-03 10:53:43 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-11-03 10:53:43 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @4190ms
2016-11-03 10:53:43 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-11-03 10:53:43 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@6e32fcb4{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 10:53:43 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @4449ms
2016-11-03 10:53:43 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-11-03 10:53:43 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-11-03 10:53:43 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-11-03 10:53:43 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59952.
2016-11-03 10:53:43 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:59952
2016-11-03 10:53:43 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 59952)
2016-11-03 10:53:43 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:59952 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 59952)
2016-11-03 10:53:43 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 59952)
2016-11-03 10:53:44 WARN  [main] org.apache.spark.SparkContext [Logging.scala:66] : Use an existing SparkContext, some configuration may not take effect.
2016-11-03 10:53:44 INFO  [main] o.a.spark.sql.internal.SharedState [Logging.scala:54] : Warehouse path is 'file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse'.
2016-11-03 10:53:48 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 55.2 MB, free 857.1 MB)
2016-11-03 10:53:48 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.9 KB, free 857.0 MB)
2016-11-03 10:53:48 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:59952 (size: 14.9 KB, free: 912.3 MB)
2016-11-03 10:53:48 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from json at SparkDataset.java:30
2016-11-03 10:53:49 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-11-03 10:53:49 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: json at SparkDataset.java:30
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (json at SparkDataset.java:30) with 2 output partitions
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (json at SparkDataset.java:30)
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SparkDataset.java:30), which has no missing parents
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 857.0 MB)
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.6 KB, free 857.0 MB)
2016-11-03 10:53:49 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:59952 (size: 2.6 KB, free: 912.3 MB)
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SparkDataset.java:30)
2016-11-03 10:53:49 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-11-03 10:53:49 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5448 bytes)
2016-11-03 10:53:49 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5448 bytes)
2016-11-03 10:53:49 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-11-03 10:53:49 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-11-03 10:53:49 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json:0+121
2016-11-03 10:53:49 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json:121+122
2016-11-03 10:53:49 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-11-03 10:53:49 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-11-03 10:53:49 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-11-03 10:53:49 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-11-03 10:53:49 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-11-03 10:53:49 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-11-03 10:53:50 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1810 bytes result sent to driver
2016-11-03 10:53:50 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1810 bytes result sent to driver
2016-11-03 10:53:50 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 921 ms on localhost (1/2)
2016-11-03 10:53:50 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 988 ms on localhost (2/2)
2016-11-03 10:53:50 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-11-03 10:53:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (json at SparkDataset.java:30) finished in 1.013 s
2016-11-03 10:53:50 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: json at SparkDataset.java:30, took 1.223764 s
2016-11-03 10:53:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 10:53:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 10:53:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<age: string, id: string, name: string ... 1 more fields>
2016-11-03 10:53:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 10:53:54 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_0_piece0 on 172.16.106.190:59952 in memory (size: 14.9 KB, free: 912.3 MB)
2016-11-03 10:53:54 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_1_piece0 on 172.16.106.190:59952 in memory (size: 2.6 KB, free: 912.3 MB)
2016-11-03 10:53:55 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 55.4 MB, free 856.9 MB)
2016-11-03 10:53:55 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 856.9 MB)
2016-11-03 10:53:55 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:59952 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 10:53:55 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from show at SparkDataset.java:33
2016-11-03 10:53:55 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 10:53:56 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 504.290374 ms
2016-11-03 10:53:56 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:33
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (show at SparkDataset.java:33) with 1 output partitions
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (show at SparkDataset.java:33)
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:33), which has no missing parents
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 7.2 KB, free 856.9 MB)
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.1 KB, free 856.9 MB)
2016-11-03 10:53:56 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:59952 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:33)
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-11-03 10:53:56 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 10:53:56 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-11-03 10:53:56 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-243, partition values: [empty row]
2016-11-03 10:53:56 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 41.056458 ms
2016-11-03 10:53:56 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 1410 bytes result sent to driver
2016-11-03 10:53:56 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 162 ms on localhost (1/1)
2016-11-03 10:53:56 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-11-03 10:53:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (show at SparkDataset.java:33) finished in 0.165 s
2016-11-03 10:53:56 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: show at SparkDataset.java:33, took 0.231780 s
2016-11-03 10:53:56 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 34.654975 ms
2016-11-03 10:53:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 10:53:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 10:53:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<name: string>
2016-11-03 10:53:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 10:53:57 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 55.6 MB, free 801.3 MB)
2016-11-03 10:53:57 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 801.3 MB)
2016-11-03 10:53:57 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:59952 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 10:53:57 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from show at SparkDataset.java:35
2016-11-03 10:53:57 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 10:53:57 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:35
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (show at SparkDataset.java:35) with 1 output partitions
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (show at SparkDataset.java:35)
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (MapPartitionsRDD[8] at show at SparkDataset.java:35), which has no missing parents
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 7.1 KB, free 801.3 MB)
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.0 KB, free 801.3 MB)
2016-11-03 10:53:57 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:59952 (size: 4.0 KB, free: 912.3 MB)
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at SparkDataset.java:35)
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-11-03 10:53:57 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 3, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 10:53:57 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 3)
2016-11-03 10:53:57 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-243, partition values: [empty row]
2016-11-03 10:53:57 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 26.542718 ms
2016-11-03 10:53:57 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 3). 1336 bytes result sent to driver
2016-11-03 10:53:57 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 3) in 56 ms on localhost (1/1)
2016-11-03 10:53:57 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-11-03 10:53:57 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (show at SparkDataset.java:35) finished in 0.060 s
2016-11-03 10:53:57 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: show at SparkDataset.java:35, took 0.093795 s
2016-11-03 10:53:57 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 45.722402 ms
2016-11-03 10:53:58 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 10:53:58 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 10:53:58 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: string>
2016-11-03 10:53:58 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 10:53:58 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 55.6 MB, free 745.7 MB)
2016-11-03 10:53:58 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.6 KB, free 745.7 MB)
2016-11-03 10:53:58 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:59952 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 10:53:58 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from describe at SparkDataset.java:36
2016-11-03 10:53:58 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 10:53:58 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: describe at SparkDataset.java:36
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 12 (describe at SparkDataset.java:36)
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (describe at SparkDataset.java:36) with 1 output partitions
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (describe at SparkDataset.java:36)
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 3)
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 3)
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 3 (MapPartitionsRDD[12] at describe at SparkDataset.java:36), which has no missing parents
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 16.1 KB, free 745.7 MB)
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.8 KB, free 745.7 MB)
2016-11-03 10:53:58 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:59952 (size: 7.8 KB, free: 912.2 MB)
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[12] at describe at SparkDataset.java:36)
2016-11-03 10:53:58 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 1 tasks
2016-11-03 10:53:58 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5844 bytes)
2016-11-03 10:53:58 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 4)
2016-11-03 10:53:58 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-243, partition values: [empty row]
2016-11-03 10:53:58 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 22.102849 ms
2016-11-03 10:53:58 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 49.872954 ms
2016-11-03 10:53:58 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 13.808013 ms
2016-11-03 10:53:58 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 66
2016-11-03 10:53:58 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:59952 in memory (size: 4.0 KB, free: 912.2 MB)
2016-11-03 10:53:58 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 158
2016-11-03 10:53:58 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:59952 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 10:53:58 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 67
2016-11-03 10:53:58 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:59952 in memory (size: 4.1 KB, free: 912.3 MB)
2016-11-03 10:53:58 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:59952 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 10:53:58 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 112
2016-11-03 10:53:58 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 113
2016-11-03 10:53:58 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 66.350783 ms
2016-11-03 10:53:58 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 11.062829 ms
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4). 1865 bytes result sent to driver
2016-11-03 10:53:59 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 4) in 885 ms on localhost (1/1)
2016-11-03 10:53:59 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 3 (describe at SparkDataset.java:36) finished in 0.886 s
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 4)
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (MapPartitionsRDD[15] at describe at SparkDataset.java:36), which has no missing parents
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 16.8 KB, free 856.6 MB)
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.0 KB, free 856.6 MB)
2016-11-03 10:53:59 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:59952 (size: 8.0 KB, free: 912.3 MB)
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at describe at SparkDataset.java:36)
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 1 tasks
2016-11-03 10:53:59 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 5, localhost, partition 0, ANY, 5190 bytes)
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 5)
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 21 ms
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 42.290469 ms
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 29.828379 ms
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 51.172927 ms
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 52.569918 ms
2016-11-03 10:53:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 5). 1954 bytes result sent to driver
2016-11-03 10:53:59 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 5) in 412 ms on localhost (1/1)
2016-11-03 10:53:59 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-11-03 10:53:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (describe at SparkDataset.java:36) finished in 0.413 s
2016-11-03 10:53:59 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: describe at SparkDataset.java:36, took 1.440638 s
2016-11-03 10:54:00 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 35.381133 ms
2016-11-03 10:54:00 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 15.399259 ms
2016-11-03 10:54:00 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 19.241121 ms
2016-11-03 10:54:00 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 10:54:00 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: select * from person
2016-11-03 10:54:01 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 10:54:01 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 10:54:01 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<age: string, id: string, name: string ... 1 more fields>
2016-11-03 10:54:01 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 10:54:01 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 55.7 MB, free 801.0 MB)
2016-11-03 10:54:01 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.6 KB, free 801.0 MB)
2016-11-03 10:54:01 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:59952 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 10:54:01 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from show at SparkDataset.java:40
2016-11-03 10:54:01 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 10:54:01 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:40
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (show at SparkDataset.java:40) with 1 output partitions
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (show at SparkDataset.java:40)
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (MapPartitionsRDD[19] at show at SparkDataset.java:40), which has no missing parents
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 7.2 KB, free 801.0 MB)
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.1 KB, free 801.0 MB)
2016-11-03 10:54:01 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:59952 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at show at SparkDataset.java:40)
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-11-03 10:54:01 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 10:54:01 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 6)
2016-11-03 10:54:01 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-243, partition values: [empty row]
2016-11-03 10:54:01 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 6). 1410 bytes result sent to driver
2016-11-03 10:54:01 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 6) in 15 ms on localhost (1/1)
2016-11-03 10:54:01 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-11-03 10:54:01 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (show at SparkDataset.java:40) finished in 0.017 s
2016-11-03 10:54:01 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: show at SparkDataset.java:40, took 0.038642 s
2016-11-03 10:54:01 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 10:54:02 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 9.751343 ms
2016-11-03 10:54:02 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: drop table if exists person
2016-11-03 10:54:02 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 10:54:02 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 10:54:02 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<age: string, id: string, name: string ... 1 more fields>
2016-11-03 10:54:02 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 10:54:02 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 55.7 MB, free 745.3 MB)
2016-11-03 10:54:02 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KB, free 745.3 MB)
2016-11-03 10:54:02 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:59952 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 10:54:02 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from collectAsList at SparkDataset.java:71
2016-11-03 10:54:02 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 10:54:02 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 47.679871 ms
2016-11-03 10:54:02 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collectAsList at SparkDataset.java:71
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 5 (collectAsList at SparkDataset.java:71) with 1 output partitions
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 6 (collectAsList at SparkDataset.java:71)
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 6 (MapPartitionsRDD[23] at collectAsList at SparkDataset.java:71), which has no missing parents
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 13.8 KB, free 745.3 MB)
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.1 KB, free 745.3 MB)
2016-11-03 10:54:02 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:59952 (size: 6.1 KB, free: 912.2 MB)
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from broadcast at DAGScheduler.scala:1012
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at collectAsList at SparkDataset.java:71)
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 6.0 with 1 tasks
2016-11-03 10:54:02 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 6.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5940 bytes)
2016-11-03 10:54:02 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 6.0 (TID 7)
2016-11-03 10:54:02 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-243, partition values: [empty row]
2016-11-03 10:54:02 ERROR [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:91] : Exception in task 0.0 in stage 6.0 (TID 7)
java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:106)
	at org.apache.spark.sql.Row$class.getInt(Row.scala:217)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:192)
	at hx.stream.spark.SparkDataset.lambda$1(SparkDataset.java:69)
	at hx.stream.spark.SparkDataset$$Lambda$8/2107849745.call(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:784)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:784)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-11-03 10:54:02 WARN  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:66] : Lost task 0.0 in stage 6.0 (TID 7, localhost): java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer
	at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:106)
	at org.apache.spark.sql.Row$class.getInt(Row.scala:217)
	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:192)
	at hx.stream.spark.SparkDataset.lambda$1(SparkDataset.java:69)
	at hx.stream.spark.SparkDataset$$Lambda$8/2107849745.call(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:784)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:784)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-11-03 10:54:02 ERROR [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:70] : Task 0 in stage 6.0 failed 1 times; aborting job
2016-11-03 10:54:02 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Cancelling stage 6
2016-11-03 10:54:02 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 6 (collectAsList at SparkDataset.java:71) failed in 0.116 s
2016-11-03 10:54:02 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 5 failed: collectAsList at SparkDataset.java:71, took 0.169625 s
2016-11-03 10:54:03 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-11-03 10:54:03 INFO  [Thread-2] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@6e32fcb4{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 10:54:03 INFO  [Thread-2] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-11-03 10:54:03 INFO  [dispatcher-event-loop-1] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-11-03 10:54:03 INFO  [Thread-2] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-11-03 10:54:03 INFO  [Thread-2] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-11-03 10:54:03 INFO  [Thread-2] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-11-03 10:54:03 INFO  [dispatcher-event-loop-3] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-11-03 10:54:03 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-11-03 10:54:03 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-11-03 10:54:03 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-91f86a93-847e-401d-9318-2a2abc2356fc
2016-11-03 11:18:04 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-11-03 11:18:04 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-11-03 11:18:04 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-11-03 11:18:04 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-11-03 11:18:04 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-11-03 11:18:04 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-11-03 11:18:04 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-11-03 11:18:05 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 60188.
2016-11-03 11:18:05 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-11-03 11:18:05 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-11-03 11:18:05 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-b5307eee-0c04-4619-9c04-4379b3ae5451
2016-11-03 11:18:05 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-11-03 11:18:05 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-11-03 11:18:05 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @2237ms
2016-11-03 11:18:05 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-11-03 11:18:05 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@4296acf5{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 11:18:05 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2419ms
2016-11-03 11:18:05 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-11-03 11:18:05 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-11-03 11:18:05 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-11-03 11:18:06 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60189.
2016-11-03 11:18:06 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:60189
2016-11-03 11:18:06 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 60189)
2016-11-03 11:18:06 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:60189 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 60189)
2016-11-03 11:18:06 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 60189)
2016-11-03 11:18:06 WARN  [main] org.apache.spark.SparkContext [Logging.scala:66] : Use an existing SparkContext, some configuration may not take effect.
2016-11-03 11:18:06 INFO  [main] o.a.spark.sql.internal.SharedState [Logging.scala:54] : Warehouse path is 'file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse'.
2016-11-03 11:18:08 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:18:08 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:18:08 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:18:08 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:18:08 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 131.9 KB, free 912.2 MB)
2016-11-03 11:18:09 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 912.2 MB)
2016-11-03 11:18:09 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:60189 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:18:09 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from show at SparkDataset.java:45
2016-11-03 11:18:09 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:18:09 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 246.40962 ms
2016-11-03 11:18:09 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:45
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (show at SparkDataset.java:45) with 1 output partitions
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (show at SparkDataset.java:45)
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:45), which has no missing parents
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 7.3 KB, free 912.1 MB)
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KB, free 912.1 MB)
2016-11-03 11:18:09 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:60189 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:18:09 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:45)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 1 tasks
2016-11-03 11:18:10 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 22.380646 ms
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1381 bytes result sent to driver
2016-11-03 11:18:10 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 176 ms on localhost (1/1)
2016-11-03 11:18:10 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (show at SparkDataset.java:45) finished in 0.196 s
2016-11-03 11:18:10 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: show at SparkDataset.java:45, took 0.368937 s
2016-11-03 11:18:10 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 27.702442 ms
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<name: string>
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:18:10 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 131.9 KB, free 912.0 MB)
2016-11-03 11:18:10 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 912.0 MB)
2016-11-03 11:18:10 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:60189 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:18:10 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from show at SparkDataset.java:47
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:18:10 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:47
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (show at SparkDataset.java:47) with 1 output partitions
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (show at SparkDataset.java:47)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:47), which has no missing parents
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.0 MB)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 912.0 MB)
2016-11-03 11:18:10 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:60189 (size: 4.0 KB, free: 912.3 MB)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:47)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-11-03 11:18:10 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 1)
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 13.772996 ms
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1). 1423 bytes result sent to driver
2016-11-03 11:18:10 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on localhost (1/1)
2016-11-03 11:18:10 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (show at SparkDataset.java:47) finished in 0.037 s
2016-11-03 11:18:10 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: show at SparkDataset.java:47, took 0.060801 s
2016-11-03 11:18:10 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 10.227174 ms
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int>
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:18:10 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 131.9 KB, free 911.9 MB)
2016-11-03 11:18:10 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 911.8 MB)
2016-11-03 11:18:10 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:60189 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 11:18:10 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from describe at SparkDataset.java:48
2016-11-03 11:18:10 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:18:10 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 38.536877 ms
2016-11-03 11:18:10 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 32.549319 ms
2016-11-03 11:18:10 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: describe at SparkDataset.java:48
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (describe at SparkDataset.java:48)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (describe at SparkDataset.java:48) with 1 output partitions
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 3 (describe at SparkDataset.java:48)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 2)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 2)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:48), which has no missing parents
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 16.9 KB, free 911.8 MB)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.8 MB)
2016-11-03 11:18:10 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:60189 (size: 7.8 KB, free: 912.2 MB)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:48)
2016-11-03 11:18:10 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-11-03 11:18:10 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5844 bytes)
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 2)
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:18:10 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 11.344357 ms
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2). 1961 bytes result sent to driver
2016-11-03 11:18:11 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2) in 242 ms on localhost (1/1)
2016-11-03 11:18:11 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 2 (describe at SparkDataset.java:48) finished in 0.243 s
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 3)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:48), which has no missing parents
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_1_piece0 on 172.16.106.190:60189 in memory (size: 4.1 KB, free: 912.2 MB)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 15.3 KB, free 911.8 MB)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.6 KB, free 911.8 MB)
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:60189 (size: 6.6 KB, free: 912.2 MB)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_0_piece0 on 172.16.106.190:60189 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:48)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 1 tasks
2016-11-03 11:18:11 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 0
2016-11-03 11:18:11 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 1
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:60189 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:18:11 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 46
2016-11-03 11:18:11 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 47
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:60189 in memory (size: 4.0 KB, free: 912.3 MB)
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5190 bytes)
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 3)
2016-11-03 11:18:11 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 92
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 4 ms
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3). 1926 bytes result sent to driver
2016-11-03 11:18:11 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3) in 39 ms on localhost (1/1)
2016-11-03 11:18:11 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 3 (describe at SparkDataset.java:48) finished in 0.040 s
2016-11-03 11:18:11 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: describe at SparkDataset.java:48, took 0.337167 s
2016-11-03 11:18:11 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 11.417441 ms
2016-11-03 11:18:11 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 11.417787 ms
2016-11-03 11:18:11 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 11.588795 ms
2016-11-03 11:18:11 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 11:18:11 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: select * from person
2016-11-03 11:18:11 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:18:11 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:18:11 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:18:11 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:18:11 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 131.9 KB, free 912.0 MB)
2016-11-03 11:18:11 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.6 KB, free 912.0 MB)
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:60189 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:18:11 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from show at SparkDataset.java:52
2016-11-03 11:18:11 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:18:11 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:52
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (show at SparkDataset.java:52) with 1 output partitions
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (show at SparkDataset.java:52)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:52), which has no missing parents
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 912.0 MB)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.1 KB, free 912.0 MB)
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:60189 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:52)
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 1 tasks
2016-11-03 11:18:11 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 4)
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:18:11 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4). 1381 bytes result sent to driver
2016-11-03 11:18:11 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4) in 15 ms on localhost (1/1)
2016-11-03 11:18:11 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-11-03 11:18:11 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (show at SparkDataset.java:52) finished in 0.016 s
2016-11-03 11:18:11 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: show at SparkDataset.java:52, took 0.031038 s
2016-11-03 11:18:11 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 11:18:12 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 9.510771 ms
2016-11-03 11:18:12 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: drop table if exists person
2016-11-03 11:18:12 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:18:12 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:18:12 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:18:12 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:18:12 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 131.9 KB, free 911.8 MB)
2016-11-03 11:18:12 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.6 KB, free 911.8 MB)
2016-11-03 11:18:12 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:60189 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 11:18:12 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from collectAsList at SparkDataset.java:83
2016-11-03 11:18:12 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:18:12 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 21.894589 ms
2016-11-03 11:18:12 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collectAsList at SparkDataset.java:83
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (collectAsList at SparkDataset.java:83) with 1 output partitions
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (collectAsList at SparkDataset.java:83)
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (MapPartitionsRDD[19] at collectAsList at SparkDataset.java:83), which has no missing parents
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 13.3 KB, free 911.8 MB)
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.1 KB, free 911.8 MB)
2016-11-03 11:18:12 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:60189 (size: 6.1 KB, free: 912.2 MB)
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at collectAsList at SparkDataset.java:83)
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-11-03 11:18:12 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5940 bytes)
2016-11-03 11:18:12 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 5)
2016-11-03 11:18:12 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:18:12 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5). 1404 bytes result sent to driver
2016-11-03 11:18:12 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5) in 18 ms on localhost (1/1)
2016-11-03 11:18:12 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-11-03 11:18:12 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (collectAsList at SparkDataset.java:83) finished in 0.018 s
2016-11-03 11:18:12 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: collectAsList at SparkDataset.java:83, took 0.030795 s
2016-11-03 11:18:12 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 12.289141 ms
2016-11-03 11:18:12 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 20.004595 ms
2016-11-03 11:18:12 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-11-03 11:18:12 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@4296acf5{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 11:18:12 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-11-03 11:18:12 INFO  [dispatcher-event-loop-1] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-11-03 11:18:12 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-11-03 11:18:12 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-11-03 11:18:12 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-11-03 11:18:12 INFO  [dispatcher-event-loop-2] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-11-03 11:18:12 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-11-03 11:18:12 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-11-03 11:18:12 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-96fdeb7f-cbaa-468a-af49-c479e3ae4d03
2016-11-03 11:20:11 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-11-03 11:20:12 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-11-03 11:20:12 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 60208.
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-11-03 11:20:12 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-eb79a3ec-f514-4546-a380-183b5cc1a0c7
2016-11-03 11:20:12 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-11-03 11:20:12 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-11-03 11:20:12 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @2938ms
2016-11-03 11:20:13 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-11-03 11:20:13 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@5439fad8{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 11:20:13 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @3102ms
2016-11-03 11:20:13 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-11-03 11:20:13 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-11-03 11:20:13 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-11-03 11:20:13 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60209.
2016-11-03 11:20:13 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:60209
2016-11-03 11:20:13 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 60209)
2016-11-03 11:20:13 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:60209 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 60209)
2016-11-03 11:20:13 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 60209)
2016-11-03 11:20:13 WARN  [main] org.apache.spark.SparkContext [Logging.scala:66] : Use an existing SparkContext, some configuration may not take effect.
2016-11-03 11:20:13 INFO  [main] o.a.spark.sql.internal.SharedState [Logging.scala:54] : Warehouse path is 'file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse'.
2016-11-03 11:20:15 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:20:15 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:20:15 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:20:15 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:20:16 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 55.3 MB, free 857.0 MB)
2016-11-03 11:20:16 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 857.0 MB)
2016-11-03 11:20:16 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:60209 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:20:16 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from show at SparkDataset.java:45
2016-11-03 11:20:16 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:20:17 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 224.98215 ms
2016-11-03 11:20:17 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:45
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (show at SparkDataset.java:45) with 1 output partitions
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (show at SparkDataset.java:45)
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:45), which has no missing parents
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 7.3 KB, free 857.0 MB)
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KB, free 857.0 MB)
2016-11-03 11:20:17 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:60209 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:45)
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 1 tasks
2016-11-03 11:20:17 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:20:17 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-11-03 11:20:17 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:20:17 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 38.360692 ms
2016-11-03 11:20:17 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1381 bytes result sent to driver
2016-11-03 11:20:17 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 220 ms on localhost (1/1)
2016-11-03 11:20:17 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-11-03 11:20:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (show at SparkDataset.java:45) finished in 0.241 s
2016-11-03 11:20:17 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: show at SparkDataset.java:45, took 0.406518 s
2016-11-03 11:20:17 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 39.471466 ms
2016-11-03 11:20:17 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:20:17 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:20:17 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<name: string>
2016-11-03 11:20:17 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:20:18 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 55.6 MB, free 801.4 MB)
2016-11-03 11:20:18 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 801.4 MB)
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:60209 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:20:18 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from show at SparkDataset.java:47
2016-11-03 11:20:18 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:20:18 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:47
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (show at SparkDataset.java:47) with 1 output partitions
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (show at SparkDataset.java:47)
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:47), which has no missing parents
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 801.4 MB)
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 801.4 MB)
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:60209 (size: 4.0 KB, free: 912.3 MB)
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:47)
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:20:18 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 1)
2016-11-03 11:20:18 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:20:18 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 24.23927 ms
2016-11-03 11:20:18 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1). 1336 bytes result sent to driver
2016-11-03 11:20:18 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1) in 55 ms on localhost (1/1)
2016-11-03 11:20:18 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-11-03 11:20:18 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (show at SparkDataset.java:47) finished in 0.056 s
2016-11-03 11:20:18 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: show at SparkDataset.java:47, took 0.073377 s
2016-11-03 11:20:18 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 25.130504 ms
2016-11-03 11:20:18 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:20:18 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:20:18 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int>
2016-11-03 11:20:18 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:20:18 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 55.6 MB, free 745.8 MB)
2016-11-03 11:20:18 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 745.8 MB)
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:60209 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 11:20:18 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from describe at SparkDataset.java:48
2016-11-03 11:20:18 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:20:18 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 58.141785 ms
2016-11-03 11:20:18 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 63.370327 ms
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:60209 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_0_piece0 on 172.16.106.190:60209 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:20:18 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 0
2016-11-03 11:20:18 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 1
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_1_piece0 on 172.16.106.190:60209 in memory (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:20:18 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 46
2016-11-03 11:20:18 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 47
2016-11-03 11:20:18 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:60209 in memory (size: 4.0 KB, free: 912.3 MB)
2016-11-03 11:20:18 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 92
2016-11-03 11:20:19 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: describe at SparkDataset.java:48
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (describe at SparkDataset.java:48)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (describe at SparkDataset.java:48) with 1 output partitions
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 3 (describe at SparkDataset.java:48)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 2)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 2)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:48), which has no missing parents
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 16.9 KB, free 856.7 MB)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KB, free 856.7 MB)
2016-11-03 11:20:19 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:60209 (size: 7.8 KB, free: 912.3 MB)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:48)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-11-03 11:20:19 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5844 bytes)
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 2)
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 25.983748 ms
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
2016-11-03 11:20:19 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2) in 135 ms on localhost (1/1)
2016-11-03 11:20:19 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 2 (describe at SparkDataset.java:48) finished in 0.136 s
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 3)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:48), which has no missing parents
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 15.3 KB, free 856.7 MB)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.6 KB, free 856.6 MB)
2016-11-03 11:20:19 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:60209 (size: 6.6 KB, free: 912.3 MB)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:48)
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 1 tasks
2016-11-03 11:20:19 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5190 bytes)
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 3)
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 3 ms
2016-11-03 11:20:19 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:60209 in memory (size: 7.8 KB, free: 912.3 MB)
2016-11-03 11:20:19 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3). 1999 bytes result sent to driver
2016-11-03 11:20:19 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3) in 389 ms on localhost (1/1)
2016-11-03 11:20:19 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-11-03 11:20:19 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 3 (describe at SparkDataset.java:48) finished in 0.390 s
2016-11-03 11:20:19 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: describe at SparkDataset.java:48, took 0.586869 s
2016-11-03 11:20:19 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 34.18057 ms
2016-11-03 11:20:19 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 7.984662 ms
2016-11-03 11:20:19 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 12.555966 ms
2016-11-03 11:20:19 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 11:20:20 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: select * from person
2016-11-03 11:20:20 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:20:20 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:20:20 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:20:20 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:20:20 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 55.6 MB, free 801.0 MB)
2016-11-03 11:20:20 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.6 KB, free 801.0 MB)
2016-11-03 11:20:20 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:60209 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:20:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from show at SparkDataset.java:52
2016-11-03 11:20:20 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:20:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:52
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (show at SparkDataset.java:52) with 1 output partitions
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (show at SparkDataset.java:52)
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:52), which has no missing parents
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 801.0 MB)
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.1 KB, free 801.0 MB)
2016-11-03 11:20:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:60209 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:52)
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 1 tasks
2016-11-03 11:20:20 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 4)
2016-11-03 11:20:20 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:20:20 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4). 1381 bytes result sent to driver
2016-11-03 11:20:20 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4) in 14 ms on localhost (1/1)
2016-11-03 11:20:20 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-11-03 11:20:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (show at SparkDataset.java:52) finished in 0.016 s
2016-11-03 11:20:20 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: show at SparkDataset.java:52, took 0.039647 s
2016-11-03 11:20:20 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 11:20:20 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 15.300092 ms
2016-11-03 11:20:20 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: drop table if exists person
2016-11-03 11:20:21 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:20:21 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:20:21 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:20:21 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:20:21 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 55.7 MB, free 745.3 MB)
2016-11-03 11:20:21 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.6 KB, free 745.3 MB)
2016-11-03 11:20:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:60209 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 11:20:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from collectAsList at SparkDataset.java:83
2016-11-03 11:20:21 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:20:21 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 40.940686 ms
2016-11-03 11:20:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collectAsList at SparkDataset.java:83
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (collectAsList at SparkDataset.java:83) with 1 output partitions
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (collectAsList at SparkDataset.java:83)
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (MapPartitionsRDD[19] at collectAsList at SparkDataset.java:83), which has no missing parents
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 13.3 KB, free 745.3 MB)
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.1 KB, free 745.3 MB)
2016-11-03 11:20:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:60209 (size: 6.1 KB, free: 912.2 MB)
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at collectAsList at SparkDataset.java:83)
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-11-03 11:20:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5940 bytes)
2016-11-03 11:20:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 5)
2016-11-03 11:20:21 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:20:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5). 1491 bytes result sent to driver
2016-11-03 11:20:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5) in 27 ms on localhost (1/1)
2016-11-03 11:20:21 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-11-03 11:20:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (collectAsList at SparkDataset.java:83) finished in 0.028 s
2016-11-03 11:20:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: collectAsList at SparkDataset.java:83, took 0.052524 s
2016-11-03 11:20:21 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 26.937579 ms
2016-11-03 11:20:21 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 60.816141 ms
2016-11-03 11:20:21 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-11-03 11:20:21 INFO  [Thread-2] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@5439fad8{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 11:20:21 INFO  [Thread-2] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-11-03 11:20:21 INFO  [dispatcher-event-loop-2] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-11-03 11:20:21 INFO  [Thread-2] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-11-03 11:20:21 INFO  [Thread-2] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-11-03 11:20:21 INFO  [Thread-2] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-11-03 11:20:21 INFO  [dispatcher-event-loop-1] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-11-03 11:20:21 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-11-03 11:20:21 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-11-03 11:20:21 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-0412cbb1-5a10-41a8-9224-0ace54af1300
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-11-03 11:55:45 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-11-03 11:55:45 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 60551.
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-11-03 11:55:45 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-11-03 11:55:46 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-aad86e37-5f10-4fa8-a5a6-6e63897307f3
2016-11-03 11:55:46 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-11-03 11:55:46 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-11-03 11:55:46 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @2497ms
2016-11-03 11:55:46 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-11-03 11:55:46 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@30665838{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 11:55:46 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2682ms
2016-11-03 11:55:46 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-11-03 11:55:46 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-11-03 11:55:46 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-11-03 11:55:46 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60552.
2016-11-03 11:55:46 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:60552
2016-11-03 11:55:46 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 60552)
2016-11-03 11:55:46 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:60552 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 60552)
2016-11-03 11:55:46 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 60552)
2016-11-03 11:55:46 WARN  [main] org.apache.spark.SparkContext [Logging.scala:66] : Use an existing SparkContext, some configuration may not take effect.
2016-11-03 11:55:46 INFO  [main] o.a.spark.sql.internal.SharedState [Logging.scala:54] : Warehouse path is 'file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse'.
2016-11-03 11:55:49 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:55:49 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:55:49 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:55:49 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:55:49 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 55.3 MB, free 857.0 MB)
2016-11-03 11:55:49 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 857.0 MB)
2016-11-03 11:55:49 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:60552 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:49 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from show at SparkDataset.java:43
2016-11-03 11:55:49 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:55:50 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 266.590823 ms
2016-11-03 11:55:50 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:43
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (show at SparkDataset.java:43) with 1 output partitions
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (show at SparkDataset.java:43)
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:43), which has no missing parents
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 7.3 KB, free 857.0 MB)
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KB, free 857.0 MB)
2016-11-03 11:55:50 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:60552 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:43)
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 1 tasks
2016-11-03 11:55:50 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:55:50 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-11-03 11:55:50 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:55:50 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 33.329652 ms
2016-11-03 11:55:50 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1381 bytes result sent to driver
2016-11-03 11:55:50 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 204 ms on localhost (1/1)
2016-11-03 11:55:50 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-11-03 11:55:50 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (show at SparkDataset.java:43) finished in 0.226 s
2016-11-03 11:55:51 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: show at SparkDataset.java:43, took 0.401643 s
2016-11-03 11:55:51 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 29.433635 ms
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<name: string>
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:55:51 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 55.6 MB, free 801.4 MB)
2016-11-03 11:55:51 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 801.4 MB)
2016-11-03 11:55:51 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:60552 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:51 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from show at SparkDataset.java:45
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:55:51 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:45
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (show at SparkDataset.java:45) with 1 output partitions
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (show at SparkDataset.java:45)
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:45), which has no missing parents
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 801.4 MB)
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 801.4 MB)
2016-11-03 11:55:51 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:60552 (size: 4.0 KB, free: 912.3 MB)
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:45)
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-11-03 11:55:51 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:55:51 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 1)
2016-11-03 11:55:51 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:55:51 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 23.413343 ms
2016-11-03 11:55:51 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1). 1336 bytes result sent to driver
2016-11-03 11:55:51 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on localhost (1/1)
2016-11-03 11:55:51 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-11-03 11:55:51 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (show at SparkDataset.java:45) finished in 0.045 s
2016-11-03 11:55:51 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: show at SparkDataset.java:45, took 0.061255 s
2016-11-03 11:55:51 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 37.462074 ms
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int>
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:55:51 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 55.6 MB, free 745.8 MB)
2016-11-03 11:55:51 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 745.8 MB)
2016-11-03 11:55:51 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:60552 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 11:55:51 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from describe at SparkDataset.java:46
2016-11-03 11:55:51 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:55:52 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 54.609095 ms
2016-11-03 11:55:52 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 63.329602 ms
2016-11-03 11:55:52 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: describe at SparkDataset.java:46
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (describe at SparkDataset.java:46)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (describe at SparkDataset.java:46) with 1 output partitions
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 3 (describe at SparkDataset.java:46)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 2)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 2)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:46), which has no missing parents
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 16.9 KB, free 745.8 MB)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KB, free 745.7 MB)
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:60552 (size: 7.8 KB, free: 912.2 MB)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:46)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5844 bytes)
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 2)
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 45.747095 ms
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_1_piece0 on 172.16.106.190:60552 in memory (size: 4.1 KB, free: 912.2 MB)
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_0_piece0 on 172.16.106.190:60552 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:52 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 0
2016-11-03 11:55:52 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 1
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:60552 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:52 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 46
2016-11-03 11:55:52 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 47
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:60552 in memory (size: 4.0 KB, free: 912.3 MB)
2016-11-03 11:55:52 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 92
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2). 1961 bytes result sent to driver
2016-11-03 11:55:52 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2) in 149 ms on localhost (1/1)
2016-11-03 11:55:52 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 2 (describe at SparkDataset.java:46) finished in 0.152 s
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 3)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:46), which has no missing parents
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 15.3 KB, free 856.7 MB)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.6 KB, free 856.6 MB)
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:60552 (size: 6.6 KB, free: 912.3 MB)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:46)
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 1 tasks
2016-11-03 11:55:52 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5190 bytes)
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 3)
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 9 ms
2016-11-03 11:55:52 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3). 1926 bytes result sent to driver
2016-11-03 11:55:52 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3) in 87 ms on localhost (1/1)
2016-11-03 11:55:52 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-11-03 11:55:52 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 3 (describe at SparkDataset.java:46) finished in 0.089 s
2016-11-03 11:55:52 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: describe at SparkDataset.java:46, took 0.317426 s
2016-11-03 11:55:52 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 34.094055 ms
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 103
2016-11-03 11:55:53 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:60552 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 93
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 94
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 95
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 96
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 97
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 98
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 99
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 100
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 101
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 0
2016-11-03 11:55:53 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:60552 in memory (size: 7.8 KB, free: 912.3 MB)
2016-11-03 11:55:53 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:60552 in memory (size: 6.6 KB, free: 912.3 MB)
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 102
2016-11-03 11:55:53 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 104
2016-11-03 11:55:53 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 20.448525 ms
2016-11-03 11:55:53 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 12.16219 ms
2016-11-03 11:55:53 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 11:55:53 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: select * from person
2016-11-03 11:55:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:55:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:55:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:55:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:55:53 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 55.6 MB, free 856.7 MB)
2016-11-03 11:55:53 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.6 KB, free 856.6 MB)
2016-11-03 11:55:53 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:60552 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:53 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from show at SparkDataset.java:50
2016-11-03 11:55:53 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:55:53 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:50
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (show at SparkDataset.java:50) with 1 output partitions
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (show at SparkDataset.java:50)
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:50), which has no missing parents
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 856.6 MB)
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.1 KB, free 856.6 MB)
2016-11-03 11:55:53 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:60552 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:50)
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 1 tasks
2016-11-03 11:55:53 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 11:55:53 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 4)
2016-11-03 11:55:53 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:55:53 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4). 1381 bytes result sent to driver
2016-11-03 11:55:53 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on localhost (1/1)
2016-11-03 11:55:53 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-11-03 11:55:53 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (show at SparkDataset.java:50) finished in 0.022 s
2016-11-03 11:55:53 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: show at SparkDataset.java:50, took 0.043106 s
2016-11-03 11:55:53 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 11:55:54 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 11.687071 ms
2016-11-03 11:55:54 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: drop table if exists person
2016-11-03 11:55:54 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: t_person
2016-11-03 11:55:54 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:55:54 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:55:54 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:55:54 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:55:54 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 55.7 MB, free 801.0 MB)
2016-11-03 11:55:54 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.6 KB, free 800.9 MB)
2016-11-03 11:55:54 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:60552 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:54 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from saveAsTable at SparkDataset.java:75
2016-11-03 11:55:54 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:55:54 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-11-03 11:55:54 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-11-03 11:55:54 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-11-03 11:55:54 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-11-03 11:55:54 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-11-03 11:55:54 INFO  [main] o.a.s.s.e.d.p.ParquetFileFormat [Logging.scala:54] : Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2016-11-03 11:55:54 INFO  [main] o.a.s.s.e.d.DefaultWriterContainer [Logging.scala:54] : Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2016-11-03 11:55:54 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: saveAsTable at SparkDataset.java:75
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (saveAsTable at SparkDataset.java:75) with 1 output partitions
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (saveAsTable at SparkDataset.java:75)
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (MapPartitionsRDD[18] at saveAsTable at SparkDataset.java:75), which has no missing parents
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 54.2 KB, free 800.9 MB)
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 800.9 MB)
2016-11-03 11:55:54 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:60552 (size: 20.4 KB, free: 912.2 MB)
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at saveAsTable at SparkDataset.java:75)
2016-11-03 11:55:54 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-11-03 11:55:54 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5948 bytes)
2016-11-03 11:55:54 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 5)
2016-11-03 11:55:54 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
2016-11-03 11:55:54 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-11-03 11:55:54 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2016-11-03 11:55:54 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2016-11-03 11:55:54 INFO  [Executor task launch worker-0] o.a.s.s.e.d.DefaultWriterContainer [Logging.scala:54] : Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2016-11-03 11:55:55 INFO  [Executor task launch worker-0] o.a.s.s.e.d.p.ParquetWriteSupport [Logging.scala:54] : Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "age",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 id;
  optional binary name (UTF8);
  optional int32 age;
}

       
2016-11-03 11:55:55 INFO  [Executor task launch worker-0] o.a.hadoop.io.compress.CodecPool [CodecPool.java:150] : Got brand-new compressor [.snappy]
2016-11-03 11:55:55 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 193
2016-11-03 11:55:55 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:60552 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 11:55:55 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 194
2016-11-03 11:55:55 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 195
2016-11-03 11:55:55 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_8_piece0 on 172.16.106.190:60552 in memory (size: 4.1 KB, free: 912.3 MB)
2016-11-03 11:55:55 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:55:55 INFO  [Executor task launch worker-0] o.a.h.m.l.o.FileOutputCommitter [FileOutputCommitter.java:439] : Saved output of task 'attempt_201611031155_0005_m_000000_0' to file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse/t_person/_temporary/0/task_201611031155_0005_m_000000
2016-11-03 11:55:55 INFO  [Executor task launch worker-0] o.a.s.mapred.SparkHadoopMapRedUtil [Logging.scala:54] : attempt_201611031155_0005_m_000000_0: Committed
2016-11-03 11:55:55 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5). 1295 bytes result sent to driver
2016-11-03 11:55:55 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5) in 791 ms on localhost (1/1)
2016-11-03 11:55:55 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-11-03 11:55:55 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (saveAsTable at SparkDataset.java:75) finished in 0.792 s
2016-11-03 11:55:55 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: saveAsTable at SparkDataset.java:75, took 0.832397 s
2016-11-03 11:55:55 INFO  [main] o.a.s.s.e.d.DefaultWriterContainer [Logging.scala:54] : Job job_201611031155_0000 committed.
2016-11-03 11:55:55 INFO  [main] o.a.s.s.e.c.CreateDataSourceTableUtils [Logging.scala:54] : Persisting data source relation `t_person` with a single input path into Hive metastore in Hive compatible format. Input path: file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse/t_person.
2016-11-03 11:55:55 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: select * from t_person
2016-11-03 11:55:55 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 11:55:55 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: string
2016-11-03 11:55:55 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 11:55:55 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 11:55:55 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: string
2016-11-03 11:55:55 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 11:55:55 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:55:55 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:55:55 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:55:55 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:55:56 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 55.8 MB, free 800.7 MB)
2016-11-03 11:55:56 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 15.1 KB, free 800.7 MB)
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:60552 (size: 15.1 KB, free: 912.3 MB)
2016-11-03 11:55:56 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from show at SparkDataset.java:76
2016-11-03 11:55:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:55:56 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 52.822541 ms
2016-11-03 11:55:56 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:76
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 5 (show at SparkDataset.java:76) with 1 output partitions
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 6 (show at SparkDataset.java:76)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 6 (MapPartitionsRDD[23] at show at SparkDataset.java:76), which has no missing parents
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 800.7 MB)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KB, free 800.7 MB)
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:60552 (size: 4.3 KB, free: 912.2 MB)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at show at SparkDataset.java:76)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 6.0 with 1 tasks
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5914 bytes)
2016-11-03 11:55:56 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 6.0 (TID 6)
2016-11-03 11:55:56 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse/t_person/part-r-00000-a2f876be-5e60-4253-acea-e793d9e14633.snappy.parquet, range: 0-722, partition values: [empty row]
2016-11-03 11:55:56 INFO  [Executor task launch worker-0] o.a.hadoop.io.compress.CodecPool [CodecPool.java:178] : Got brand-new decompressor [.snappy]
2016-11-03 11:55:56 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 6). 1559 bytes result sent to driver
2016-11-03 11:55:56 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 6) in 139 ms on localhost (1/1)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 6 (show at SparkDataset.java:76) finished in 0.137 s
2016-11-03 11:55:56 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-11-03 11:55:56 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 5 finished: show at SparkDataset.java:76, took 0.168173 s
2016-11-03 11:55:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 11:55:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 11:55:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 11:55:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 11:55:56 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13 stored as values in memory (estimated size 55.8 MB, free 744.9 MB)
2016-11-03 11:55:56 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.6 KB, free 744.9 MB)
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_13_piece0 in memory on 172.16.106.190:60552 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 11:55:56 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 13 from collectAsList at SparkDataset.java:87
2016-11-03 11:55:56 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 11:55:56 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 36.263574 ms
2016-11-03 11:55:56 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collectAsList at SparkDataset.java:87
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 6 (collectAsList at SparkDataset.java:87) with 1 output partitions
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 7 (collectAsList at SparkDataset.java:87)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 7 (MapPartitionsRDD[26] at collectAsList at SparkDataset.java:87), which has no missing parents
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14 stored as values in memory (estimated size 12.8 KB, free 744.8 MB)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.8 KB, free 744.8 MB)
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_14_piece0 in memory on 172.16.106.190:60552 (size: 5.8 KB, free: 912.2 MB)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 14 from broadcast at DAGScheduler.scala:1012
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[26] at collectAsList at SparkDataset.java:87)
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 1 tasks
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5940 bytes)
2016-11-03 11:55:56 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 7)
2016-11-03 11:55:56 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 11:55:56 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 7). 1404 bytes result sent to driver
2016-11-03 11:55:56 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 7) in 31 ms on localhost (1/1)
2016-11-03 11:55:56 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-11-03 11:55:56 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 7 (collectAsList at SparkDataset.java:87) finished in 0.032 s
2016-11-03 11:55:56 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 6 finished: collectAsList at SparkDataset.java:87, took 0.044302 s
2016-11-03 11:55:56 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 19.95715 ms
2016-11-03 11:55:56 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 32.903894 ms
2016-11-03 11:55:56 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-11-03 11:55:56 INFO  [Thread-2] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@30665838{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 11:55:56 INFO  [Thread-2] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-1] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-11-03 11:55:56 INFO  [Thread-2] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-11-03 11:55:56 INFO  [Thread-2] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-11-03 11:55:56 INFO  [Thread-2] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-11-03 11:55:56 INFO  [dispatcher-event-loop-1] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-11-03 11:55:56 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-11-03 11:55:56 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-11-03 11:55:56 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-1c44f922-3d29-45af-92be-dddf62fd47a1
2016-11-03 12:00:28 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-11-03 12:00:28 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-11-03 12:00:29 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 60581.
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-11-03 12:00:29 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-acdbe99c-c4b7-4f46-ae36-0039d9aa30a2
2016-11-03 12:00:29 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-11-03 12:00:29 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-11-03 12:00:29 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @2519ms
2016-11-03 12:00:29 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-11-03 12:00:29 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@7329300e{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 12:00:29 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2670ms
2016-11-03 12:00:29 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-11-03 12:00:29 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-11-03 12:00:30 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-11-03 12:00:30 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60582.
2016-11-03 12:00:30 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:60582
2016-11-03 12:00:30 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 60582)
2016-11-03 12:00:30 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:60582 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 60582)
2016-11-03 12:00:30 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 60582)
2016-11-03 12:00:30 WARN  [main] org.apache.spark.SparkContext [Logging.scala:66] : Use an existing SparkContext, some configuration may not take effect.
2016-11-03 12:00:30 INFO  [main] o.a.spark.sql.internal.SharedState [Logging.scala:54] : Warehouse path is 'file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse'.
2016-11-03 12:00:32 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 12:00:32 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 12:00:32 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 12:00:32 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 12:00:33 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 55.3 MB, free 857.0 MB)
2016-11-03 12:00:33 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.6 KB, free 857.0 MB)
2016-11-03 12:00:33 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:60582 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 12:00:33 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from show at SparkDataset.java:43
2016-11-03 12:00:33 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 12:00:33 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 264.68464 ms
2016-11-03 12:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:43
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (show at SparkDataset.java:43) with 1 output partitions
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (show at SparkDataset.java:43)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:43), which has no missing parents
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 7.3 KB, free 857.0 MB)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KB, free 857.0 MB)
2016-11-03 12:00:34 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:60582 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at SparkDataset.java:43)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 1 tasks
2016-11-03 12:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 26.598988 ms
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1381 bytes result sent to driver
2016-11-03 12:00:34 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 210 ms on localhost (1/1)
2016-11-03 12:00:34 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (show at SparkDataset.java:43) finished in 0.233 s
2016-11-03 12:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: show at SparkDataset.java:43, took 0.392100 s
2016-11-03 12:00:34 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 29.671941 ms
2016-11-03 12:00:34 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 12:00:34 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 12:00:34 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<name: string>
2016-11-03 12:00:34 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 12:00:34 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 55.6 MB, free 801.4 MB)
2016-11-03 12:00:34 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.6 KB, free 801.4 MB)
2016-11-03 12:00:34 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:60582 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 12:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from show at SparkDataset.java:45
2016-11-03 12:00:34 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 12:00:34 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:45
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (show at SparkDataset.java:45) with 1 output partitions
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 1 (show at SparkDataset.java:45)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:45), which has no missing parents
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 801.4 MB)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 801.4 MB)
2016-11-03 12:00:34 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:60582 (size: 4.0 KB, free: 912.3 MB)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at SparkDataset.java:45)
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 1 tasks
2016-11-03 12:00:34 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 1)
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 21.0546 ms
2016-11-03 12:00:34 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1). 1336 bytes result sent to driver
2016-11-03 12:00:34 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on localhost (1/1)
2016-11-03 12:00:34 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-11-03 12:00:34 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 1 (show at SparkDataset.java:45) finished in 0.046 s
2016-11-03 12:00:34 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: show at SparkDataset.java:45, took 0.068198 s
2016-11-03 12:00:34 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 30.923101 ms
2016-11-03 12:00:35 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 12:00:35 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 12:00:35 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int>
2016-11-03 12:00:35 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 12:00:35 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 55.6 MB, free 745.8 MB)
2016-11-03 12:00:35 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.6 KB, free 745.8 MB)
2016-11-03 12:00:35 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:60582 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 12:00:35 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from describe at SparkDataset.java:46
2016-11-03 12:00:35 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 12:00:35 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 56.269882 ms
2016-11-03 12:00:35 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 58.6948 ms
2016-11-03 12:00:35 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: describe at SparkDataset.java:46
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 8 (describe at SparkDataset.java:46)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (describe at SparkDataset.java:46) with 1 output partitions
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 3 (describe at SparkDataset.java:46)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 2)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 2)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:46), which has no missing parents
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 16.9 KB, free 745.8 MB)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KB, free 745.7 MB)
2016-11-03 12:00:35 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:60582 (size: 7.8 KB, free: 912.2 MB)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at describe at SparkDataset.java:46)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 1 tasks
2016-11-03 12:00:35 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5844 bytes)
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 2)
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 24.411903 ms
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2). 1888 bytes result sent to driver
2016-11-03 12:00:35 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 2) in 125 ms on localhost (1/1)
2016-11-03 12:00:35 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 2 (describe at SparkDataset.java:46) finished in 0.127 s
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 3)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:46), which has no missing parents
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 15.3 KB, free 745.7 MB)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.6 KB, free 745.7 MB)
2016-11-03 12:00:35 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:60582 (size: 6.6 KB, free: 912.2 MB)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at describe at SparkDataset.java:46)
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 3.0 with 1 tasks
2016-11-03 12:00:35 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5190 bytes)
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 3.0 (TID 3)
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 9 ms
2016-11-03 12:00:35 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3). 1926 bytes result sent to driver
2016-11-03 12:00:35 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 3.0 (TID 3) in 75 ms on localhost (1/1)
2016-11-03 12:00:35 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-11-03 12:00:35 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 3 (describe at SparkDataset.java:46) finished in 0.078 s
2016-11-03 12:00:35 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: describe at SparkDataset.java:46, took 0.270737 s
2016-11-03 12:00:36 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 39.894806 ms
2016-11-03 12:00:36 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_0_piece0 on 172.16.106.190:60582 in memory (size: 14.6 KB, free: 912.2 MB)
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 0
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 1
2016-11-03 12:00:36 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:60582 in memory (size: 6.6 KB, free: 912.3 MB)
2016-11-03 12:00:36 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_1_piece0 on 172.16.106.190:60582 in memory (size: 4.1 KB, free: 912.3 MB)
2016-11-03 12:00:36 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_2_piece0 on 172.16.106.190:60582 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 46
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 47
2016-11-03 12:00:36 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:60582 in memory (size: 4.0 KB, free: 912.3 MB)
2016-11-03 12:00:36 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 17.770263 ms
2016-11-03 12:00:36 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:60582 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 92
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 93
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 94
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 95
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 96
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 97
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 98
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 99
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 100
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 101
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 102
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 103
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 104
2016-11-03 12:00:36 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned shuffle 0
2016-11-03 12:00:36 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:60582 in memory (size: 7.8 KB, free: 912.3 MB)
2016-11-03 12:00:36 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 19.497361 ms
2016-11-03 12:00:36 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 12:00:36 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: select * from person
2016-11-03 12:00:36 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 12:00:36 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 12:00:36 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 12:00:36 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 12:00:37 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 55.6 MB, free 856.7 MB)
2016-11-03 12:00:37 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.6 KB, free 856.6 MB)
2016-11-03 12:00:37 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:60582 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 12:00:37 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from show at SparkDataset.java:50
2016-11-03 12:00:37 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 12:00:37 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:50
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (show at SparkDataset.java:50) with 1 output partitions
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 4 (show at SparkDataset.java:50)
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:50), which has no missing parents
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 7.3 KB, free 856.6 MB)
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.1 KB, free 856.6 MB)
2016-11-03 12:00:37 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:60582 (size: 4.1 KB, free: 912.3 MB)
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at show at SparkDataset.java:50)
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 1 tasks
2016-11-03 12:00:37 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5855 bytes)
2016-11-03 12:00:37 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 4)
2016-11-03 12:00:37 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 12:00:37 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4). 1381 bytes result sent to driver
2016-11-03 12:00:37 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 4) in 20 ms on localhost (1/1)
2016-11-03 12:00:37 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-11-03 12:00:37 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 4 (show at SparkDataset.java:50) finished in 0.022 s
2016-11-03 12:00:37 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: show at SparkDataset.java:50, took 0.047520 s
2016-11-03 12:00:37 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: person
2016-11-03 12:00:37 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 14.603146 ms
2016-11-03 12:00:37 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: drop table if exists person
2016-11-03 12:00:37 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: t_person
2016-11-03 12:00:37 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 12:00:37 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 12:00:37 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 12:00:37 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 12:00:37 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 55.7 MB, free 801.0 MB)
2016-11-03 12:00:37 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.6 KB, free 800.9 MB)
2016-11-03 12:00:37 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:60582 (size: 14.6 KB, free: 912.3 MB)
2016-11-03 12:00:37 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from saveAsTable at SparkDataset.java:83
2016-11-03 12:00:37 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 12:00:37 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-11-03 12:00:37 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-11-03 12:00:37 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-11-03 12:00:37 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-11-03 12:00:37 INFO  [main] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-11-03 12:00:37 INFO  [main] o.a.s.s.e.d.p.ParquetFileFormat [Logging.scala:54] : Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2016-11-03 12:00:38 INFO  [main] o.a.s.s.e.d.DefaultWriterContainer [Logging.scala:54] : Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2016-11-03 12:00:38 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: saveAsTable at SparkDataset.java:83
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 19 (saveAsTable at SparkDataset.java:83)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (saveAsTable at SparkDataset.java:83) with 1 output partitions
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 6 (saveAsTable at SparkDataset.java:83)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 5)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 5)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 5 (MapPartitionsRDD[19] at saveAsTable at SparkDataset.java:83), which has no missing parents
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 8.7 KB, free 800.9 MB)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.8 KB, free 800.9 MB)
2016-11-03 12:00:38 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:60582 (size: 4.8 KB, free: 912.3 MB)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[19] at saveAsTable at SparkDataset.java:83)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 1 tasks
2016-11-03 12:00:38 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, PROCESS_LOCAL, 5937 bytes)
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 5)
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5). 1643 bytes result sent to driver
2016-11-03 12:00:38 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 5) in 21 ms on localhost (1/1)
2016-11-03 12:00:38 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 5 (saveAsTable at SparkDataset.java:83) finished in 0.023 s
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 6)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 6 (ShuffledRowRDD[20] at saveAsTable at SparkDataset.java:83), which has no missing parents
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11 stored as values in memory (estimated size 51.2 KB, free 800.9 MB)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.8 KB, free 800.9 MB)
2016-11-03 12:00:38 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_11_piece0 in memory on 172.16.106.190:60582 (size: 18.8 KB, free: 912.2 MB)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 6 (ShuffledRowRDD[20] at saveAsTable at SparkDataset.java:83)
2016-11-03 12:00:38 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 6.0 with 1 tasks
2016-11-03 12:00:38 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, ANY, 5283 bytes)
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 6.0 (TID 6)
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 1 non-empty blocks out of 1 blocks
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.s.s.e.d.DefaultWriterContainer [Logging.scala:54] : Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.s.s.e.d.p.ParquetWriteSupport [Logging.scala:54] : Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "name",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "age",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 id;
  optional binary name (UTF8);
  optional int32 age;
}

       
2016-11-03 12:00:38 INFO  [Executor task launch worker-0] o.a.hadoop.io.compress.CodecPool [CodecPool.java:150] : Got brand-new compressor [.snappy]
2016-11-03 12:00:38 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 194
2016-11-03 12:00:38 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:60582 in memory (size: 14.6 KB, free: 912.3 MB)
2016-11-03 12:00:38 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 195
2016-11-03 12:00:38 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_8_piece0 on 172.16.106.190:60582 in memory (size: 4.1 KB, free: 912.3 MB)
2016-11-03 12:00:38 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner [Logging.scala:54] : Cleaned accumulator 241
2016-11-03 12:00:38 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_10_piece0 on 172.16.106.190:60582 in memory (size: 4.8 KB, free: 912.3 MB)
2016-11-03 12:00:39 INFO  [Executor task launch worker-0] o.a.h.m.l.o.FileOutputCommitter [FileOutputCommitter.java:439] : Saved output of task 'attempt_201611031200_0006_m_000000_0' to file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse/t_person/_temporary/0/task_201611031200_0006_m_000000
2016-11-03 12:00:39 INFO  [Executor task launch worker-0] o.a.s.mapred.SparkHadoopMapRedUtil [Logging.scala:54] : attempt_201611031200_0006_m_000000_0: Committed
2016-11-03 12:00:39 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 6). 1691 bytes result sent to driver
2016-11-03 12:00:39 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 6.0 (TID 6) in 884 ms on localhost (1/1)
2016-11-03 12:00:39 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 6 (saveAsTable at SparkDataset.java:83) finished in 0.885 s
2016-11-03 12:00:39 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: saveAsTable at SparkDataset.java:83, took 0.973081 s
2016-11-03 12:00:39 INFO  [main] o.a.s.s.e.d.DefaultWriterContainer [Logging.scala:54] : Job job_201611031200_0000 committed.
2016-11-03 12:00:39 INFO  [main] o.a.s.s.e.c.CreateDataSourceTableUtils [Logging.scala:54] : Persisting data source relation `t_person` with a single input path into Hive metastore in Hive compatible format. Input path: file:/Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse/t_person.
2016-11-03 12:00:39 INFO  [main] o.a.s.sql.execution.SparkSqlParser [Logging.scala:54] : Parsing command: select * from t_person
2016-11-03 12:00:39 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 12:00:39 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: string
2016-11-03 12:00:39 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 12:00:39 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 12:00:39 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: string
2016-11-03 12:00:39 INFO  [main] o.a.s.s.c.parser.CatalystSqlParser [Logging.scala:54] : Parsing command: int
2016-11-03 12:00:39 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 12:00:39 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 12:00:39 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 12:00:39 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 12:00:39 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12 stored as values in memory (estimated size 55.8 MB, free 800.7 MB)
2016-11-03 12:00:39 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.1 KB, free 800.7 MB)
2016-11-03 12:00:39 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_12_piece0 in memory on 172.16.106.190:60582 (size: 15.1 KB, free: 912.3 MB)
2016-11-03 12:00:39 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 12 from show at SparkDataset.java:84
2016-11-03 12:00:39 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 12:00:39 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 86.711905 ms
2016-11-03 12:00:39 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: show at SparkDataset.java:84
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 5 (show at SparkDataset.java:84) with 1 output partitions
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 7 (show at SparkDataset.java:84)
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 7 (MapPartitionsRDD[25] at show at SparkDataset.java:84), which has no missing parents
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13 stored as values in memory (estimated size 8.7 KB, free 800.7 MB)
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.3 KB, free 800.7 MB)
2016-11-03 12:00:39 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_13_piece0 in memory on 172.16.106.190:60582 (size: 4.3 KB, free: 912.2 MB)
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 13 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at show at SparkDataset.java:84)
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 7.0 with 1 tasks
2016-11-03 12:00:39 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, PROCESS_LOCAL, 5914 bytes)
2016-11-03 12:00:39 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 7.0 (TID 7)
2016-11-03 12:00:39 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/spark-warehouse/t_person/part-r-00000-1e84952b-0232-4678-a352-cf0cf2151375.snappy.parquet, range: 0-722, partition values: [empty row]
2016-11-03 12:00:39 INFO  [Executor task launch worker-0] o.a.hadoop.io.compress.CodecPool [CodecPool.java:178] : Got brand-new decompressor [.snappy]
2016-11-03 12:00:39 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 7). 1472 bytes result sent to driver
2016-11-03 12:00:39 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 7.0 (TID 7) in 122 ms on localhost (1/1)
2016-11-03 12:00:39 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-11-03 12:00:39 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 7 (show at SparkDataset.java:84) finished in 0.122 s
2016-11-03 12:00:39 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 5 finished: show at SparkDataset.java:84, took 0.139665 s
2016-11-03 12:00:40 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruning directories with: 
2016-11-03 12:00:40 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Post-Scan Filters: 
2016-11-03 12:00:40 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pruned Data Schema: struct<id: int, name: string, age: int ... 1 more fields>
2016-11-03 12:00:40 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Pushed Filters: 
2016-11-03 12:00:40 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14 stored as values in memory (estimated size 55.8 MB, free 744.9 MB)
2016-11-03 12:00:40 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.6 KB, free 744.9 MB)
2016-11-03 12:00:40 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_14_piece0 in memory on 172.16.106.190:60582 (size: 14.6 KB, free: 912.2 MB)
2016-11-03 12:00:40 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 14 from collectAsList at SparkDataset.java:95
2016-11-03 12:00:40 INFO  [main] o.a.s.s.e.d.FileSourceStrategy [Logging.scala:54] : Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2016-11-03 12:00:40 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 118.792145 ms
2016-11-03 12:00:40 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collectAsList at SparkDataset.java:95
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 6 (collectAsList at SparkDataset.java:95) with 1 output partitions
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 8 (collectAsList at SparkDataset.java:95)
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 8 (MapPartitionsRDD[28] at collectAsList at SparkDataset.java:95), which has no missing parents
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_15 stored as values in memory (estimated size 12.8 KB, free 744.9 MB)
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.8 KB, free 744.8 MB)
2016-11-03 12:00:40 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_15_piece0 in memory on 172.16.106.190:60582 (size: 5.8 KB, free: 912.2 MB)
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 15 from broadcast at DAGScheduler.scala:1012
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[28] at collectAsList at SparkDataset.java:95)
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 1 tasks
2016-11-03 12:00:40 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 8, localhost, partition 0, PROCESS_LOCAL, 5940 bytes)
2016-11-03 12:00:40 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 8)
2016-11-03 12:00:40 INFO  [Executor task launch worker-0] o.a.s.s.e.datasources.FileScanRDD [Logging.scala:54] : Reading File path: file:///Users/Benchun/Documents/Engineering/eclipse/big-architecture/stream-pipeline/src/main/resources/person.json, range: 0-223, partition values: [empty row]
2016-11-03 12:00:40 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 8). 1404 bytes result sent to driver
2016-11-03 12:00:40 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 8) in 13 ms on localhost (1/1)
2016-11-03 12:00:40 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-11-03 12:00:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 8 (collectAsList at SparkDataset.java:95) finished in 0.014 s
2016-11-03 12:00:40 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 6 finished: collectAsList at SparkDataset.java:95, took 0.037491 s
2016-11-03 12:00:40 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 110.591191 ms
2016-11-03 12:00:41 INFO  [main] o.a.s.s.c.e.codegen.CodeGenerator [Logging.scala:54] : Code generated in 31.187103 ms
2016-11-03 12:00:41 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-11-03 12:00:41 INFO  [Thread-2] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@7329300e{HTTP/1.1}{0.0.0.0:4040}
2016-11-03 12:00:41 INFO  [Thread-2] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-11-03 12:00:41 INFO  [dispatcher-event-loop-1] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-11-03 12:00:41 INFO  [Thread-2] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-11-03 12:00:41 INFO  [Thread-2] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-11-03 12:00:41 INFO  [Thread-2] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-11-03 12:00:41 INFO  [dispatcher-event-loop-1] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-11-03 12:00:41 INFO  [Thread-2] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-11-03 12:00:41 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-11-03 12:00:41 INFO  [Thread-2] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-725817b6-b795-421f-85ba-bd25d073c41c
