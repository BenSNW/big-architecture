2016-09-30 11:55:19 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:22] : starting spark-streaming-kafka
2016-09-30 11:55:19 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-09-30 11:55:21 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-30 11:55:21 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-09-30 11:55:21 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-09-30 11:55:21 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-09-30 11:55:21 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-09-30 11:55:21 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-09-30 11:55:21 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 53098.
2016-09-30 11:55:21 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-09-30 11:55:21 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-09-30 11:55:21 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-7615f0cf-9681-441f-bac6-a741f73329a3
2016-09-30 11:55:22 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-09-30 11:55:22 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-09-30 11:55:22 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @3569ms
2016-09-30 11:55:22 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-09-30 11:55:22 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@3fa2213{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 11:55:22 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @3730ms
2016-09-30 11:55:22 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-09-30 11:55:22 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-09-30 11:55:22 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-09-30 11:55:22 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53099.
2016-09-30 11:55:22 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:53099
2016-09-30 11:55:22 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 53099)
2016-09-30 11:55:22 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:53099 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 53099)
2016-09-30 11:55:22 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 53099)
2016-09-30 11:55:23 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-09-30 11:55:23 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-09-30 11:55:23 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:53099 (size: 10.2 KB, free: 912.3 MB)
2016-09-30 11:55:23 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkApplication.java:28
2016-09-30 11:55:23 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 11:55:23 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: count at SparkApplication.java:28
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (count at SparkApplication.java:28) with 2 output partitions
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (count at SparkApplication.java:28)
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:28), which has no missing parents
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 912.2 MB)
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1897.0 B, free 912.2 MB)
2016-09-30 11:55:23 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:53099 (size: 1897.0 B, free: 912.3 MB)
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:28)
2016-09-30 11:55:23 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5305 bytes)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5305 bytes)
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1041 bytes result sent to driver
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1041 bytes result sent to driver
2016-09-30 11:55:24 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 121 ms on localhost (1/2)
2016-09-30 11:55:24 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 260 ms on localhost (2/2)
2016-09-30 11:55:24 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (count at SparkApplication.java:28) finished in 0.294 s
2016-09-30 11:55:24 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: count at SparkApplication.java:28, took 0.461204 s
2016-09-30 11:55:24 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:28] : readme lines: 95
2016-09-30 11:55:24 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 59.6 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:53099 (size: 14.3 KB, free: 912.3 MB)
2016-09-30 11:55:24 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from textFile at SparkApplication.java:30
2016-09-30 11:55:24 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 11:55:24 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkApplication.java:55
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 5 (mapToPair at SparkApplication.java:43)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (collect at SparkApplication.java:55) with 2 output partitions
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (collect at SparkApplication.java:55)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:43), which has no missing parents
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 5.5 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:53099 (size: 3.1 KB, free: 912.3 MB)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:43)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5378 bytes)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5378 bytes)
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_1 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_1 in memory on 172.16.106.190:53099 (size: 4.9 KB, free: 912.3 MB)
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_0 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_0 in memory on 172.16.106.190:53099 (size: 5.7 KB, free: 912.3 MB)
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2175 bytes result sent to driver
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2262 bytes result sent to driver
2016-09-30 11:55:24 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 146 ms on localhost (1/2)
2016-09-30 11:55:24 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 150 ms on localhost (2/2)
2016-09-30 11:55:24 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (mapToPair at SparkApplication.java:43) finished in 0.151 s
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:54), which has no missing parents
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 912.1 MB)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:53099 (size: 2.2 KB, free: 912.3 MB)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 2 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:54)
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 2 tasks
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, ANY, 5140 bytes)
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, ANY, 5140 bytes)
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 2.0 (TID 5)
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 4)
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 5 ms
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 7 ms
2016-09-30 11:55:24 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5). 4678 bytes result sent to driver
2016-09-30 11:55:24 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4). 4790 bytes result sent to driver
2016-09-30 11:55:24 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5) in 89 ms on localhost (1/2)
2016-09-30 11:55:24 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4) in 92 ms on localhost (2/2)
2016-09-30 11:55:24 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-30 11:55:24 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (collect at SparkApplication.java:55) finished in 0.093 s
2016-09-30 11:55:24 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: collect at SparkApplication.java:55, took 0.306578 s
2016-09-30 11:55:24 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-09-30 11:55:24 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@3fa2213{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 11:55:24 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-3] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-09-30 11:55:24 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-09-30 11:55:24 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-09-30 11:55:24 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-09-30 11:55:24 INFO  [dispatcher-event-loop-3] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-09-30 11:55:24 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-09-30 11:55:24 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-09-30 11:55:24 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-0d65944a-49b2-45b6-a99f-3ef6aaa72d68
2016-09-30 12:04:12 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:23] : starting spark-streaming-kafka
2016-09-30 12:04:13 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-09-30 12:04:13 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-30 12:04:13 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-09-30 12:04:13 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-09-30 12:04:13 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-09-30 12:04:13 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-09-30 12:04:13 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-09-30 12:04:13 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 53181.
2016-09-30 12:04:13 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-09-30 12:04:14 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-09-30 12:04:14 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-f6831e0b-0c23-491a-9712-f5b00a251797
2016-09-30 12:04:14 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-09-30 12:04:14 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-09-30 12:04:14 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @2214ms
2016-09-30 12:04:14 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-09-30 12:04:14 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@6f0b0a5e{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:04:14 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2373ms
2016-09-30 12:04:14 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-09-30 12:04:14 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-09-30 12:04:14 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-09-30 12:04:14 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53182.
2016-09-30 12:04:14 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:53182
2016-09-30 12:04:14 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 53182)
2016-09-30 12:04:14 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:53182 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 53182)
2016-09-30 12:04:14 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 53182)
2016-09-30 12:04:15 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-09-30 12:04:15 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-09-30 12:04:15 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:53182 (size: 10.2 KB, free: 912.3 MB)
2016-09-30 12:04:15 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkApplication.java:29
2016-09-30 12:04:16 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:04:16 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: count at SparkApplication.java:29
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (count at SparkApplication.java:29) with 2 output partitions
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (count at SparkApplication.java:29)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29), which has no missing parents
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 912.2 MB)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1897.0 B, free 912.2 MB)
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:53182 (size: 1897.0 B, free: 912.3 MB)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1041 bytes result sent to driver
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1041 bytes result sent to driver
2016-09-30 12:04:16 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 199 ms on localhost (1/2)
2016-09-30 12:04:16 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 87 ms on localhost (2/2)
2016-09-30 12:04:16 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (count at SparkApplication.java:29) finished in 0.233 s
2016-09-30 12:04:16 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: count at SparkApplication.java:29, took 0.386744 s
2016-09-30 12:04:16 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:29] : readme lines: 95
2016-09-30 12:04:16 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 59.6 KB, free 912.1 MB)
2016-09-30 12:04:16 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:53182 (size: 14.3 KB, free: 912.3 MB)
2016-09-30 12:04:16 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from textFile at SparkApplication.java:31
2016-09-30 12:04:16 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:04:16 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:56
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 5 (mapToPair at SparkApplication.java:45)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (sortByKey at SparkApplication.java:56) with 2 output partitions
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (sortByKey at SparkApplication.java:56)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:45), which has no missing parents
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 5.5 KB, free 912.1 MB)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 912.1 MB)
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:53182 (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:45)
2016-09-30 12:04:16 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:04:16 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_1 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-09-30 12:04:16 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_0 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_1 in memory on 172.16.106.190:53182 (size: 4.9 KB, free: 912.3 MB)
2016-09-30 12:04:16 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_0 in memory on 172.16.106.190:53182 (size: 5.7 KB, free: 912.3 MB)
2016-09-30 12:04:16 ERROR [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:91] : Exception in task 1.0 in stage 1.0 (TID 3)
java.util.regex.PatternSyntaxException: Unclosed character class near index 17
[\.|,|"|'|-|/|:|\s
                 ^
	at java.util.regex.Pattern.error(Pattern.java:1955)
	at java.util.regex.Pattern.clazz(Pattern.java:2548)
	at java.util.regex.Pattern.sequence(Pattern.java:2063)
	at java.util.regex.Pattern.expr(Pattern.java:1996)
	at java.util.regex.Pattern.compile(Pattern.java:1696)
	at java.util.regex.Pattern.<init>(Pattern.java:1351)
	at java.util.regex.Pattern.compile(Pattern.java:1028)
	at java.lang.String.split(String.java:2368)
	at java.lang.String.split(String.java:2410)
	at hx.stream.spark.SparkApplication$1.call(SparkApplication.java:39)
	at hx.stream.spark.SparkApplication$1.call(SparkApplication.java:1)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:124)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:124)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:192)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-30 12:04:16 ERROR [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:91] : Exception in task 0.0 in stage 1.0 (TID 2)
java.util.regex.PatternSyntaxException: Unclosed character class near index 17
[\.|,|"|'|-|/|:|\s
                 ^
	at java.util.regex.Pattern.error(Pattern.java:1955)
	at java.util.regex.Pattern.clazz(Pattern.java:2548)
	at java.util.regex.Pattern.sequence(Pattern.java:2063)
	at java.util.regex.Pattern.expr(Pattern.java:1996)
	at java.util.regex.Pattern.compile(Pattern.java:1696)
	at java.util.regex.Pattern.<init>(Pattern.java:1351)
	at java.util.regex.Pattern.compile(Pattern.java:1028)
	at java.lang.String.split(String.java:2368)
	at java.lang.String.split(String.java:2410)
	at hx.stream.spark.SparkApplication$1.call(SparkApplication.java:39)
	at hx.stream.spark.SparkApplication$1.call(SparkApplication.java:1)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:124)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:124)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:192)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-09-30 12:04:17 WARN  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:66] : Lost task 1.0 in stage 1.0 (TID 3, localhost): java.util.regex.PatternSyntaxException: Unclosed character class near index 17
[\.|,|"|'|-|/|:|\s
                 ^
	at java.util.regex.Pattern.error(Pattern.java:1955)
	at java.util.regex.Pattern.clazz(Pattern.java:2548)
	at java.util.regex.Pattern.sequence(Pattern.java:2063)
	at java.util.regex.Pattern.expr(Pattern.java:1996)
	at java.util.regex.Pattern.compile(Pattern.java:1696)
	at java.util.regex.Pattern.<init>(Pattern.java:1351)
	at java.util.regex.Pattern.compile(Pattern.java:1028)
	at java.lang.String.split(String.java:2368)
	at java.lang.String.split(String.java:2410)
	at hx.stream.spark.SparkApplication$1.call(SparkApplication.java:39)
	at hx.stream.spark.SparkApplication$1.call(SparkApplication.java:1)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:124)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:124)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:192)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-09-30 12:04:17 ERROR [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:70] : Task 1 in stage 1.0 failed 1 times; aborting job
2016-09-30 12:04:17 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 12:04:17 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Lost task 0.0 in stage 1.0 (TID 2) on executor localhost: java.util.regex.PatternSyntaxException (Unclosed character class near index 17
[\.|,|"|'|-|/|:|\s
                 ^) [duplicate 1]
2016-09-30 12:04:17 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 12:04:17 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Cancelling stage 1
2016-09-30 12:04:17 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (mapToPair at SparkApplication.java:45) failed in 0.121 s
2016-09-30 12:04:17 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 failed: sortByKey at SparkApplication.java:56, took 0.153492 s
2016-09-30 12:04:17 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-09-30 12:04:17 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@6f0b0a5e{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:04:17 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-09-30 12:04:17 INFO  [dispatcher-event-loop-0] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-09-30 12:04:17 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-09-30 12:04:17 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-09-30 12:04:17 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-09-30 12:04:17 INFO  [dispatcher-event-loop-3] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-09-30 12:04:17 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-09-30 12:04:17 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-09-30 12:04:17 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-ab1bce1d-4eea-4834-be45-549f4677df9a
2016-09-30 12:04:41 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:23] : starting spark-streaming-kafka
2016-09-30 12:04:41 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-09-30 12:04:41 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-09-30 12:04:42 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 53194.
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-09-30 12:04:42 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-c157b7a2-e24a-4904-9604-e698f20e8593
2016-09-30 12:04:42 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-09-30 12:04:42 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-09-30 12:04:42 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1844ms
2016-09-30 12:04:42 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-09-30 12:04:42 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@f1172b2{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:04:42 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @1958ms
2016-09-30 12:04:42 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-09-30 12:04:42 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-09-30 12:04:42 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-09-30 12:04:42 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53195.
2016-09-30 12:04:42 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:53195
2016-09-30 12:04:42 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 53195)
2016-09-30 12:04:42 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:53195 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 53195)
2016-09-30 12:04:42 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 53195)
2016-09-30 12:04:43 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-09-30 12:04:43 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-09-30 12:04:43 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:53195 (size: 10.2 KB, free: 912.3 MB)
2016-09-30 12:04:43 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkApplication.java:29
2016-09-30 12:04:43 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:04:43 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: count at SparkApplication.java:29
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (count at SparkApplication.java:29) with 2 output partitions
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (count at SparkApplication.java:29)
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29), which has no missing parents
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 912.2 MB)
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1897.0 B, free 912.2 MB)
2016-09-30 12:04:43 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:53195 (size: 1897.0 B, free: 912.3 MB)
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29)
2016-09-30 12:04:43 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1041 bytes result sent to driver
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1041 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 189 ms on localhost (1/2)
2016-09-30 12:04:44 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 80 ms on localhost (2/2)
2016-09-30 12:04:44 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (count at SparkApplication.java:29) finished in 0.208 s
2016-09-30 12:04:44 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: count at SparkApplication.java:29, took 0.334839 s
2016-09-30 12:04:44 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:29] : readme lines: 95
2016-09-30 12:04:44 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 59.6 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:53195 (size: 14.3 KB, free: 912.3 MB)
2016-09-30 12:04:44 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from textFile at SparkApplication.java:31
2016-09-30 12:04:44 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:04:44 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:56
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 5 (mapToPair at SparkApplication.java:45)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (sortByKey at SparkApplication.java:56) with 2 output partitions
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (sortByKey at SparkApplication.java:56)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:45), which has no missing parents
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 5.5 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:53195 (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:45)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_1 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_0 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_1 in memory on 172.16.106.190:53195 (size: 4.9 KB, free: 912.3 MB)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_0 in memory on 172.16.106.190:53195 (size: 5.7 KB, free: 912.3 MB)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2262 bytes result sent to driver
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2175 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 149 ms on localhost (1/2)
2016-09-30 12:04:44 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 146 ms on localhost (2/2)
2016-09-30 12:04:44 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (mapToPair at SparkApplication.java:45) finished in 0.151 s
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:56), which has no missing parents
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:53195 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:56)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 2 tasks
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, ANY, 5142 bytes)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, ANY, 5142 bytes)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 4)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 2.0 (TID 5)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 3 ms
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4). 2435 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4) in 82 ms on localhost (1/2)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5). 2341 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5) in 85 ms on localhost (2/2)
2016-09-30 12:04:44 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (sortByKey at SparkApplication.java:56) finished in 0.089 s
2016-09-30 12:04:44 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: sortByKey at SparkApplication.java:56, took 0.292854 s
2016-09-30 12:04:44 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkApplication.java:57
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (reduceByKey at SparkApplication.java:56)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (collect at SparkApplication.java:57) with 2 output partitions
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (collect at SparkApplication.java:57)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 4)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 4)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:56), which has no missing parents
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:53195 (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:56)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 1882 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 49 ms on localhost (1/2)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 1882 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 55 ms on localhost (2/2)
2016-09-30 12:04:44 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 4 (reduceByKey at SparkApplication.java:56) finished in 0.057 s
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 5)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:56), which has no missing parents
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 912.1 MB)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:53195 (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:56)
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 2 tasks
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 5.0 (TID 9)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 8)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:04:44 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9). 4593 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9) in 40 ms on localhost (1/2)
2016-09-30 12:04:44 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8). 4718 bytes result sent to driver
2016-09-30 12:04:44 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8) in 44 ms on localhost (2/2)
2016-09-30 12:04:44 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-09-30 12:04:44 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (collect at SparkApplication.java:57) finished in 0.045 s
2016-09-30 12:04:44 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: collect at SparkApplication.java:57, took 0.139625 s
2016-09-30 12:04:44 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-09-30 12:04:44 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@f1172b2{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:04:44 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-0] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-09-30 12:04:44 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-09-30 12:04:44 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-09-30 12:04:44 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-09-30 12:04:44 INFO  [dispatcher-event-loop-3] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-09-30 12:04:44 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-09-30 12:04:44 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-09-30 12:04:44 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-cece362d-a38d-4d4e-afdf-108f1c17dba4
2016-09-30 12:09:18 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:23] : starting spark-streaming-kafka
2016-09-30 12:09:18 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-09-30 12:09:18 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-30 12:09:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-09-30 12:09:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-09-30 12:09:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-09-30 12:09:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-09-30 12:09:18 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-09-30 12:09:19 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 53222.
2016-09-30 12:09:19 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-09-30 12:09:19 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-09-30 12:09:19 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-8fd32d21-04c6-44e7-b2e5-bad6795a4234
2016-09-30 12:09:19 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-09-30 12:09:19 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-09-30 12:09:19 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1997ms
2016-09-30 12:09:19 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-09-30 12:09:19 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@b5e615b{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:09:19 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2173ms
2016-09-30 12:09:19 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-09-30 12:09:19 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-09-30 12:09:19 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-09-30 12:09:19 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53223.
2016-09-30 12:09:19 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:53223
2016-09-30 12:09:19 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 53223)
2016-09-30 12:09:19 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:53223 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 53223)
2016-09-30 12:09:19 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 53223)
2016-09-30 12:09:20 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-09-30 12:09:20 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-09-30 12:09:20 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:53223 (size: 10.2 KB, free: 912.3 MB)
2016-09-30 12:09:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkApplication.java:29
2016-09-30 12:09:20 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:09:20 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: count at SparkApplication.java:29
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (count at SparkApplication.java:29) with 2 output partitions
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (count at SparkApplication.java:29)
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29), which has no missing parents
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 912.2 MB)
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1897.0 B, free 912.2 MB)
2016-09-30 12:09:20 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:53223 (size: 1897.0 B, free: 912.3 MB)
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29)
2016-09-30 12:09:20 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1041 bytes result sent to driver
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1041 bytes result sent to driver
2016-09-30 12:09:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 85 ms on localhost (1/2)
2016-09-30 12:09:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 219 ms on localhost (2/2)
2016-09-30 12:09:21 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (count at SparkApplication.java:29) finished in 0.238 s
2016-09-30 12:09:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: count at SparkApplication.java:29, took 0.350866 s
2016-09-30 12:09:21 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:29] : readme lines: 95
2016-09-30 12:09:21 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 59.6 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:53223 (size: 14.3 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from textFile at SparkApplication.java:31
2016-09-30 12:09:21 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:09:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:57
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 5 (mapToPair at SparkApplication.java:46)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (sortByKey at SparkApplication.java:57) with 2 output partitions
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (sortByKey at SparkApplication.java:57)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:46), which has no missing parents
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 5.5 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:53223 (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:46)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_1 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_0 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_1 in memory on 172.16.106.190:53223 (size: 4.9 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_0 in memory on 172.16.106.190:53223 (size: 5.7 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2262 bytes result sent to driver
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2262 bytes result sent to driver
2016-09-30 12:09:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 136 ms on localhost (1/2)
2016-09-30 12:09:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 140 ms on localhost (2/2)
2016-09-30 12:09:21 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (mapToPair at SparkApplication.java:46) finished in 0.142 s
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:53223 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:57)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 2 tasks
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, ANY, 5142 bytes)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, ANY, 5142 bytes)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 2.0 (TID 5)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 4)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5). 2482 bytes result sent to driver
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4). 2434 bytes result sent to driver
2016-09-30 12:09:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5) in 79 ms on localhost (1/2)
2016-09-30 12:09:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4) in 82 ms on localhost (2/2)
2016-09-30 12:09:21 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (sortByKey at SparkApplication.java:57) finished in 0.083 s
2016-09-30 12:09:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: sortByKey at SparkApplication.java:57, took 0.283490 s
2016-09-30 12:09:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkApplication.java:58
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (reduceByKey at SparkApplication.java:57)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (collect at SparkApplication.java:58) with 2 output partitions
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (collect at SparkApplication.java:58)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 4)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 4)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:53223 (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:57)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 1882 bytes result sent to driver
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 1882 bytes result sent to driver
2016-09-30 12:09:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 51 ms on localhost (1/2)
2016-09-30 12:09:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 53 ms on localhost (2/2)
2016-09-30 12:09:21 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 4 (reduceByKey at SparkApplication.java:57) finished in 0.055 s
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 5)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:53223 (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 2 tasks
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 5.0 (TID 9)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 8)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8). 4853 bytes result sent to driver
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9). 4543 bytes result sent to driver
2016-09-30 12:09:21 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8) in 53 ms on localhost (1/2)
2016-09-30 12:09:21 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9) in 53 ms on localhost (2/2)
2016-09-30 12:09:21 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (collect at SparkApplication.java:58) finished in 0.056 s
2016-09-30 12:09:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: collect at SparkApplication.java:58, took 0.147351 s
2016-09-30 12:09:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:61
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (sortByKey at SparkApplication.java:61) with 2 output partitions
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 8 (sortByKey at SparkApplication.java:61)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 7)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:61), which has no missing parents
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:53223 (size: 2.8 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:61)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 2 tasks
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:53223 in memory (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 10, localhost, partition 0, ANY, 5143 bytes)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 8.0 (TID 11, localhost, partition 1, ANY, 5143 bytes)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 10)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:53223 in memory (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:53223 in memory (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:53223 in memory (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 8.0 (TID 11)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11). 2225 bytes result sent to driver
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10). 2235 bytes result sent to driver
2016-09-30 12:09:21 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11) in 41 ms on localhost (1/2)
2016-09-30 12:09:21 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10) in 44 ms on localhost (2/2)
2016-09-30 12:09:21 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 8 (sortByKey at SparkApplication.java:61) finished in 0.045 s
2016-09-30 12:09:21 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: sortByKey at SparkApplication.java:61, took 0.065410 s
2016-09-30 12:09:21 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkApplication.java:61
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 10 (mapToPair at SparkApplication.java:60)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (foreach at SparkApplication.java:61) with 2 output partitions
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 12 (foreach at SparkApplication.java:61)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 11)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 11)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:60), which has no missing parents
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:53223 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:60)
2016-09-30 12:09:21 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 2 tasks
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:09:21 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 11.0 (TID 13, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:09:21 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 12)
2016-09-30 12:09:21 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 11.0 (TID 13)
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13). 1882 bytes result sent to driver
2016-09-30 12:09:22 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13) in 29 ms on localhost (1/2)
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12). 1882 bytes result sent to driver
2016-09-30 12:09:22 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12) in 35 ms on localhost (2/2)
2016-09-30 12:09:22 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 11 (mapToPair at SparkApplication.java:60) finished in 0.035 s
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:61), which has no missing parents
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:53223 (size: 2.4 KB, free: 912.3 MB)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:61)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 2 tasks
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 14, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 12.0 (TID 15, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 12.0 (TID 15)
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 14)
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14). 1553 bytes result sent to driver
2016-09-30 12:09:22 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14) in 20 ms on localhost (1/2)
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15). 1553 bytes result sent to driver
2016-09-30 12:09:22 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15) in 33 ms on localhost (2/2)
2016-09-30 12:09:22 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 12 (foreach at SparkApplication.java:61) finished in 0.036 s
2016-09-30 12:09:22 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: foreach at SparkApplication.java:61, took 0.095768 s
2016-09-30 12:09:22 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkApplication.java:62
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 5 (collect at SparkApplication.java:62) with 2 output partitions
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 15 (collect at SparkApplication.java:62)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 14)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 15 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.0 KB, free 912.1 MB)
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_10_piece0 in memory on 172.16.106.190:53223 (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 15 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57)
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 15.0 with 2 tasks
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 15.0 (TID 16, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 15.0 (TID 17, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 15.0 (TID 17)
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 15.0 (TID 16)
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:22 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 17). 4456 bytes result sent to driver
2016-09-30 12:09:22 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 15.0 (TID 17) in 25 ms on localhost (1/2)
2016-09-30 12:09:22 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 16). 4940 bytes result sent to driver
2016-09-30 12:09:22 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 15.0 (TID 16) in 32 ms on localhost (2/2)
2016-09-30 12:09:22 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 15.0, whose tasks have all completed, from pool 
2016-09-30 12:09:22 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 15 (collect at SparkApplication.java:62) finished in 0.033 s
2016-09-30 12:09:22 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 5 finished: collect at SparkApplication.java:62, took 0.046386 s
2016-09-30 12:09:22 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-09-30 12:09:22 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@b5e615b{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:09:22 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-2] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-09-30 12:09:22 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-09-30 12:09:22 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-09-30 12:09:22 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-09-30 12:09:22 INFO  [dispatcher-event-loop-2] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-09-30 12:09:22 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-09-30 12:09:22 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-09-30 12:09:22 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-024e14d9-37aa-4fd8-9cc8-06793dfe2b69
2016-09-30 12:09:45 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:23] : starting spark-streaming-kafka
2016-09-30 12:09:45 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-09-30 12:09:45 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-09-30 12:09:46 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 53230.
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-09-30 12:09:46 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-93b43b92-6bb4-439e-9bb9-be15bd886b63
2016-09-30 12:09:46 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-09-30 12:09:46 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-09-30 12:09:46 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1761ms
2016-09-30 12:09:46 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-09-30 12:09:46 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@6f0b0a5e{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:09:46 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @1888ms
2016-09-30 12:09:46 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-09-30 12:09:46 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-09-30 12:09:46 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-09-30 12:09:46 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53231.
2016-09-30 12:09:46 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:53231
2016-09-30 12:09:46 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 53231)
2016-09-30 12:09:46 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:53231 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 53231)
2016-09-30 12:09:46 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 53231)
2016-09-30 12:09:47 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-09-30 12:09:47 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-09-30 12:09:47 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:53231 (size: 10.2 KB, free: 912.3 MB)
2016-09-30 12:09:47 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkApplication.java:29
2016-09-30 12:09:47 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:09:47 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: count at SparkApplication.java:29
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (count at SparkApplication.java:29) with 2 output partitions
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (count at SparkApplication.java:29)
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29), which has no missing parents
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 912.2 MB)
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1897.0 B, free 912.2 MB)
2016-09-30 12:09:47 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:53231 (size: 1897.0 B, free: 912.3 MB)
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29)
2016-09-30 12:09:47 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1041 bytes result sent to driver
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1041 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 79 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 202 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (count at SparkApplication.java:29) finished in 0.221 s
2016-09-30 12:09:48 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: count at SparkApplication.java:29, took 0.359066 s
2016-09-30 12:09:48 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:29] : readme lines: 95
2016-09-30 12:09:48 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 59.6 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:53231 (size: 14.3 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from textFile at SparkApplication.java:31
2016-09-30 12:09:48 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:09:48 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:57
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 5 (mapToPair at SparkApplication.java:46)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (sortByKey at SparkApplication.java:57) with 2 output partitions
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (sortByKey at SparkApplication.java:57)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:46), which has no missing parents
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 5.5 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:53231 (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:46)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_1 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_1 in memory on 172.16.106.190:53231 (size: 4.9 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_0 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_0 in memory on 172.16.106.190:53231 (size: 5.7 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2262 bytes result sent to driver
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2262 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 131 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 134 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (mapToPair at SparkApplication.java:46) finished in 0.136 s
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:53231 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:57)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, ANY, 5142 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, ANY, 5142 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 2.0 (TID 5)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 4)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 6 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5). 2395 bytes result sent to driver
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4). 2347 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5) in 69 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4) in 72 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (sortByKey at SparkApplication.java:57) finished in 0.072 s
2016-09-30 12:09:48 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: sortByKey at SparkApplication.java:57, took 0.271502 s
2016-09-30 12:09:48 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkApplication.java:58
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (reduceByKey at SparkApplication.java:57)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (collect at SparkApplication.java:58) with 2 output partitions
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (collect at SparkApplication.java:58)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 4)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 4)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:53231 (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:57)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 1882 bytes result sent to driver
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 1882 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 45 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 45 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 4 (reduceByKey at SparkApplication.java:57) finished in 0.047 s
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 5)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:53231 (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 8)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 5.0 (TID 9)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8). 4940 bytes result sent to driver
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9). 4456 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8) in 41 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9) in 41 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (collect at SparkApplication.java:58) finished in 0.042 s
2016-09-30 12:09:48 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: collect at SparkApplication.java:58, took 0.130287 s
2016-09-30 12:09:48 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:60
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (sortByKey at SparkApplication.java:60) with 2 output partitions
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 8 (sortByKey at SparkApplication.java:60)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 7)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:60), which has no missing parents
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:53231 (size: 2.8 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:60)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 10, localhost, partition 0, ANY, 5143 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 8.0 (TID 11, localhost, partition 1, ANY, 5143 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 10)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 8.0 (TID 11)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:53231 in memory (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:53231 in memory (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:53231 in memory (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:53231 in memory (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10). 2322 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10) in 27 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11). 2225 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11) in 27 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 8 (sortByKey at SparkApplication.java:60) finished in 0.030 s
2016-09-30 12:09:48 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: sortByKey at SparkApplication.java:60, took 0.050092 s
2016-09-30 12:09:48 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkApplication.java:61
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 10 (mapToPair at SparkApplication.java:60)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (foreach at SparkApplication.java:61) with 2 output partitions
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 12 (foreach at SparkApplication.java:61)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 11)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 11)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:60), which has no missing parents
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:53231 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:60)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 11.0 (TID 13, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 11.0 (TID 13)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 12)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13). 1882 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13) in 22 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12). 1882 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12) in 26 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 11 (mapToPair at SparkApplication.java:60) finished in 0.026 s
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:60), which has no missing parents
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:53231 (size: 2.4 KB, free: 912.3 MB)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:60)
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 2 tasks
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 14, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 12.0 (TID 15, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 12.0 (TID 15)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 14)
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 2 ms
2016-09-30 12:09:48 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14). 1553 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14) in 15 ms on localhost (1/2)
2016-09-30 12:09:48 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15). 1553 bytes result sent to driver
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15) in 23 ms on localhost (2/2)
2016-09-30 12:09:48 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-09-30 12:09:48 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 12 (foreach at SparkApplication.java:61) finished in 0.025 s
2016-09-30 12:09:48 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: foreach at SparkApplication.java:61, took 0.074325 s
2016-09-30 12:09:48 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-09-30 12:09:48 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@6f0b0a5e{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:09:48 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-2] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-09-30 12:09:48 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-09-30 12:09:48 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-09-30 12:09:48 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-09-30 12:09:48 INFO  [dispatcher-event-loop-0] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-09-30 12:09:48 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-09-30 12:09:48 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-09-30 12:09:48 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-faf1be45-d0f0-4381-b496-70e637c7ec7d
2016-09-30 12:10:38 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:23] : starting spark-streaming-kafka
2016-09-30 12:10:38 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-09-30 12:10:38 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-09-30 12:10:39 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 53238.
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-09-30 12:10:39 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-4b905b01-cef4-4502-ad16-f9fd6fc8a724
2016-09-30 12:10:39 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-09-30 12:10:39 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-09-30 12:10:39 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1869ms
2016-09-30 12:10:39 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-09-30 12:10:39 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@2efac2c0{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:10:39 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @2044ms
2016-09-30 12:10:39 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-09-30 12:10:39 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-09-30 12:10:39 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-09-30 12:10:40 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53239.
2016-09-30 12:10:40 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:53239
2016-09-30 12:10:40 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 53239)
2016-09-30 12:10:40 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:53239 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 53239)
2016-09-30 12:10:40 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 53239)
2016-09-30 12:10:40 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-09-30 12:10:40 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-09-30 12:10:40 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:53239 (size: 10.2 KB, free: 912.3 MB)
2016-09-30 12:10:40 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkApplication.java:29
2016-09-30 12:10:40 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:10:40 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: count at SparkApplication.java:29
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (count at SparkApplication.java:29) with 2 output partitions
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (count at SparkApplication.java:29)
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29), which has no missing parents
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 912.2 MB)
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1897.0 B, free 912.2 MB)
2016-09-30 12:10:40 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:53239 (size: 1897.0 B, free: 912.3 MB)
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:29)
2016-09-30 12:10:40 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1041 bytes result sent to driver
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1041 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 207 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 87 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (count at SparkApplication.java:29) finished in 0.225 s
2016-09-30 12:10:41 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: count at SparkApplication.java:29, took 0.330336 s
2016-09-30 12:10:41 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:29] : readme lines: 95
2016-09-30 12:10:41 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 59.6 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:53239 (size: 14.3 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from textFile at SparkApplication.java:31
2016-09-30 12:10:41 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:10:41 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:57
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 5 (mapToPair at SparkApplication.java:46)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (sortByKey at SparkApplication.java:57) with 2 output partitions
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (sortByKey at SparkApplication.java:57)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:46), which has no missing parents
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 5.5 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:53239 (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:46)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_1 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_1 in memory on 172.16.106.190:53239 (size: 4.9 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_0 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_0 in memory on 172.16.106.190:53239 (size: 5.7 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2175 bytes result sent to driver
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2262 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 134 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 132 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (mapToPair at SparkApplication.java:46) finished in 0.138 s
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:53239 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:57)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, ANY, 5142 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, ANY, 5142 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 2.0 (TID 5)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 4)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 5 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 5 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4). 2447 bytes result sent to driver
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5). 2318 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4) in 74 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5) in 72 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (sortByKey at SparkApplication.java:57) finished in 0.075 s
2016-09-30 12:10:41 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: sortByKey at SparkApplication.java:57, took 0.263656 s
2016-09-30 12:10:41 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkApplication.java:58
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (reduceByKey at SparkApplication.java:57)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (collect at SparkApplication.java:58) with 2 output partitions
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (collect at SparkApplication.java:58)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 4)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 4)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:53239 (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:57)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 1882 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 50 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 1882 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 51 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 4 (reduceByKey at SparkApplication.java:57) finished in 0.052 s
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 5)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57), which has no missing parents
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:53239 (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:57)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 8)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 5.0 (TID 9)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9). 4166 bytes result sent to driver
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8). 4672 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9) in 37 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8) in 39 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (collect at SparkApplication.java:58) finished in 0.041 s
2016-09-30 12:10:41 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: collect at SparkApplication.java:58, took 0.131262 s
2016-09-30 12:10:41 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:60
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (sortByKey at SparkApplication.java:60) with 2 output partitions
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 8 (sortByKey at SparkApplication.java:60)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 7)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:60), which has no missing parents
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:53239 (size: 2.8 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:60)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 10, localhost, partition 0, ANY, 5143 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 8.0 (TID 11, localhost, partition 1, ANY, 5143 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 10)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:53239 in memory (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 8.0 (TID 11)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:53239 in memory (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:53239 in memory (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:53239 in memory (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11). 2225 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11) in 27 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10). 2225 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10) in 31 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 8 (sortByKey at SparkApplication.java:60) finished in 0.032 s
2016-09-30 12:10:41 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: sortByKey at SparkApplication.java:60, took 0.048639 s
2016-09-30 12:10:41 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkApplication.java:61
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 10 (mapToPair at SparkApplication.java:60)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (foreach at SparkApplication.java:61) with 2 output partitions
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 12 (foreach at SparkApplication.java:61)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 11)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 11)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:60), which has no missing parents
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:53239 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:60)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 11.0 (TID 13, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 12)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 11.0 (TID 13)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13). 1882 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13) in 25 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12). 1882 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12) in 28 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-1] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 11 (mapToPair at SparkApplication.java:60) finished in 0.029 s
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:60), which has no missing parents
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:53239 (size: 2.4 KB, free: 912.3 MB)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:60)
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 2 tasks
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 14, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:10:41 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 12.0 (TID 15, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 12.0 (TID 15)
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 14)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:10:41 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14). 1640 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14) in 20 ms on localhost (1/2)
2016-09-30 12:10:41 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15). 1553 bytes result sent to driver
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15) in 26 ms on localhost (2/2)
2016-09-30 12:10:41 INFO  [task-result-getter-2] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-09-30 12:10:41 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 12 (foreach at SparkApplication.java:61) finished in 0.028 s
2016-09-30 12:10:41 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: foreach at SparkApplication.java:61, took 0.078842 s
2016-09-30 12:10:41 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-09-30 12:10:41 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@2efac2c0{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:10:42 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-09-30 12:10:42 INFO  [dispatcher-event-loop-0] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-09-30 12:10:42 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-09-30 12:10:42 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-09-30 12:10:42 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-09-30 12:10:42 INFO  [dispatcher-event-loop-1] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-09-30 12:10:42 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-09-30 12:10:42 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-09-30 12:10:42 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-7f6b9cf5-a0b0-4a4a-a808-a54edc1499d9
2016-09-30 12:11:56 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:24] : starting spark-streaming-kafka
2016-09-30 12:11:56 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Running Spark version 2.0.0
2016-09-30 12:11:57 WARN  [main] o.a.hadoop.util.NativeCodeLoader [NativeCodeLoader.java:62] : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls to: Benchun
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls to: Benchun
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing view acls groups to: 
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : Changing modify acls groups to: 
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SecurityManager [Logging.scala:54] : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Benchun); groups with view permissions: Set(); users  with modify permissions: Set(Benchun); groups with modify permissions: Set()
2016-09-30 12:11:57 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'sparkDriver' on port 53245.
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering MapOutputTracker
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering BlockManagerMaster
2016-09-30 12:11:57 INFO  [main] o.a.spark.storage.DiskBlockManager [Logging.scala:54] : Created local directory at /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/blockmgr-7f5260be-ab00-4d65-af32-09f71c31dfb8
2016-09-30 12:11:57 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore started with capacity 912.3 MB
2016-09-30 12:11:57 INFO  [main] org.apache.spark.SparkEnv [Logging.scala:54] : Registering OutputCommitCoordinator
2016-09-30 12:11:57 INFO  [main] org.spark_project.jetty.util.log [Log.java:186] : Logging initialized @1869ms
2016-09-30 12:11:57 INFO  [main] o.spark_project.jetty.server.Server [Server.java:327] : jetty-9.2.z-SNAPSHOT
2016-09-30 12:11:57 INFO  [main] o.s.jetty.server.ServerConnector [AbstractConnector.java:266] : Started ServerConnector@6f0b0a5e{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:11:57 INFO  [main] o.spark_project.jetty.server.Server [Server.java:379] : Started @1997ms
2016-09-30 12:11:57 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'SparkUI' on port 4040.
2016-09-30 12:11:57 INFO  [main] org.apache.spark.ui.SparkUI [Logging.scala:54] : Bound SparkUI to 0.0.0.0, and started at http://172.16.106.190:4040
2016-09-30 12:11:58 INFO  [main] org.apache.spark.executor.Executor [Logging.scala:54] : Starting executor ID driver on host localhost
2016-09-30 12:11:58 INFO  [main] org.apache.spark.util.Utils [Logging.scala:54] : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53246.
2016-09-30 12:11:58 INFO  [main] o.a.s.n.n.NettyBlockTransferService [Logging.scala:54] : Server created on 172.16.106.190:53246
2016-09-30 12:11:58 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registering BlockManager BlockManagerId(driver, 172.16.106.190, 53246)
2016-09-30 12:11:58 INFO  [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint [Logging.scala:54] : Registering block manager 172.16.106.190:53246 with 912.3 MB RAM, BlockManagerId(driver, 172.16.106.190, 53246)
2016-09-30 12:11:58 INFO  [main] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : Registered BlockManager BlockManagerId(driver, 172.16.106.190, 53246)
2016-09-30 12:11:58 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 912.2 MB)
2016-09-30 12:11:58 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.2 KB, free 912.2 MB)
2016-09-30 12:11:58 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_0_piece0 in memory on 172.16.106.190:53246 (size: 10.2 KB, free: 912.3 MB)
2016-09-30 12:11:58 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 0 from textFile at SparkApplication.java:30
2016-09-30 12:11:59 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:11:59 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: count at SparkApplication.java:30
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 0 (count at SparkApplication.java:30) with 2 output partitions
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 0 (count at SparkApplication.java:30)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List()
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:30), which has no missing parents
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 912.2 MB)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_1_piece0 stored as bytes in memory (estimated size 1897.0 B, free 912.2 MB)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_1_piece0 in memory on 172.16.106.190:53246 (size: 1897.0 B, free: 912.3 MB)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 0 (file:///usr/local/Cellar/apache-spark/1.6.1/README.md MapPartitionsRDD[1] at textFile at SparkApplication.java:30)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 0.0 with 2 tasks
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5305 bytes)
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 0.0 (TID 1)
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 0.0 (TID 0)
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] o.a.h.c.Configuration.deprecation [Configuration.java:840] : mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1). 1041 bytes result sent to driver
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0). 1041 bytes result sent to driver
2016-09-30 12:11:59 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 0.0 (TID 0) in 221 ms on localhost (1/2)
2016-09-30 12:11:59 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 0.0 (TID 1) in 86 ms on localhost (2/2)
2016-09-30 12:11:59 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 0 (count at SparkApplication.java:30) finished in 0.240 s
2016-09-30 12:11:59 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 0 finished: count at SparkApplication.java:30, took 0.365796 s
2016-09-30 12:11:59 INFO  [main] hx.stream.spark.SparkApplication [SparkApplication.java:30] : readme lines: 95
2016-09-30 12:11:59 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2 stored as values in memory (estimated size 59.6 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [main] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_2_piece0 in memory on 172.16.106.190:53246 (size: 14.3 KB, free: 912.3 MB)
2016-09-30 12:11:59 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 2 from textFile at SparkApplication.java:32
2016-09-30 12:11:59 INFO  [main] o.a.hadoop.mapred.FileInputFormat [FileInputFormat.java:253] : Total input paths to process : 1
2016-09-30 12:11:59 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:59
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 5 (mapToPair at SparkApplication.java:48)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 1 (sortByKey at SparkApplication.java:59) with 2 output partitions
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 2 (sortByKey at SparkApplication.java:59)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 1)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 1)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:48), which has no missing parents
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3 stored as values in memory (estimated size 5.5 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_3_piece0 in memory on 172.16.106.190:53246 (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at mapToPair at SparkApplication.java:48)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 1.0 with 2 tasks
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, PROCESS_LOCAL, 5380 bytes)
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 1.0 (TID 2)
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 1.0 (TID 3)
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:1679+1680
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] org.apache.spark.rdd.HadoopRDD [Logging.scala:54] : Input split: file:/usr/local/Cellar/apache-spark/1.6.1/README.md:0+1679
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_1 stored as values in memory (estimated size 4.9 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block rdd_3_0 stored as values in memory (estimated size 5.7 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_1 in memory on 172.16.106.190:53246 (size: 4.9 KB, free: 912.3 MB)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added rdd_3_0 in memory on 172.16.106.190:53246 (size: 5.7 KB, free: 912.3 MB)
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2). 2262 bytes result sent to driver
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3). 2262 bytes result sent to driver
2016-09-30 12:11:59 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 1.0 (TID 2) in 136 ms on localhost (1/2)
2016-09-30 12:11:59 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 1.0 (TID 3) in 135 ms on localhost (2/2)
2016-09-30 12:11:59 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 1 (mapToPair at SparkApplication.java:48) finished in 0.140 s
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 2)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:59), which has no missing parents
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4 stored as values in memory (estimated size 4.6 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_4_piece0 in memory on 172.16.106.190:53246 (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at sortByKey at SparkApplication.java:59)
2016-09-30 12:11:59 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 2.0 with 2 tasks
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0, ANY, 5142 bytes)
2016-09-30 12:11:59 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1, ANY, 5142 bytes)
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 2.0 (TID 4)
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 2.0 (TID 5)
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:11:59 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 5 ms
2016-09-30 12:11:59 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 4 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5). 2405 bytes result sent to driver
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4). 2362 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 2.0 (TID 5) in 74 ms on localhost (1/2)
2016-09-30 12:12:00 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 2.0 (TID 4) in 78 ms on localhost (2/2)
2016-09-30 12:12:00 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 2 (sortByKey at SparkApplication.java:59) finished in 0.079 s
2016-09-30 12:12:00 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 1 finished: sortByKey at SparkApplication.java:59, took 0.275470 s
2016-09-30 12:12:00 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: collect at SparkApplication.java:60
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 6 (reduceByKey at SparkApplication.java:59)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 2 (collect at SparkApplication.java:60) with 2 output partitions
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 5 (collect at SparkApplication.java:60)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 4)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 4)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:59), which has no missing parents
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.5 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-2] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_5_piece0 in memory on 172.16.106.190:53246 (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 4 (ShuffledRDD[6] at reduceByKey at SparkApplication.java:59)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 4.0 with 2 tasks
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 4.0 (TID 6)
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 4.0 (TID 7)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6). 1882 bytes result sent to driver
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7). 1882 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 4.0 (TID 6) in 48 ms on localhost (1/2)
2016-09-30 12:12:00 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 4.0 (TID 7) in 46 ms on localhost (2/2)
2016-09-30 12:12:00 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 4 (reduceByKey at SparkApplication.java:59) finished in 0.049 s
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 5)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:59), which has no missing parents
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_6_piece0 in memory on 172.16.106.190:53246 (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 5 (ShuffledRDD[9] at sortByKey at SparkApplication.java:59)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 5.0 with 2 tasks
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 5.0 (TID 9, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 5.0 (TID 9)
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 5.0 (TID 8)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 2 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9). 4230 bytes result sent to driver
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8). 4671 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 5.0 (TID 9) in 43 ms on localhost (1/2)
2016-09-30 12:12:00 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 5.0 (TID 8) in 45 ms on localhost (2/2)
2016-09-30 12:12:00 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 5 (collect at SparkApplication.java:60) finished in 0.046 s
2016-09-30 12:12:00 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 2 finished: collect at SparkApplication.java:60, took 0.125980 s
2016-09-30 12:12:00 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: sortByKey at SparkApplication.java:62
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 0 is 159 bytes
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.MapOutputTrackerMaster [Logging.scala:54] : Size of output statuses for shuffle 1 is 159 bytes
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 3 (sortByKey at SparkApplication.java:62) with 2 output partitions
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 8 (sortByKey at SparkApplication.java:62)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 7)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List()
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:62), which has no missing parents
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_7_piece0 in memory on 172.16.106.190:53246 (size: 2.8 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at sortByKey at SparkApplication.java:62)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 8.0 with 2 tasks
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 8.0 (TID 10, localhost, partition 0, ANY, 5143 bytes)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 8.0 (TID 11, localhost, partition 1, ANY, 5143 bytes)
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 8.0 (TID 10)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 8.0 (TID 11)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10). 2230 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 8.0 (TID 10) in 28 ms on localhost (1/2)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11). 2220 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 8.0 (TID 11) in 32 ms on localhost (2/2)
2016-09-30 12:12:00 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 8 (sortByKey at SparkApplication.java:62) finished in 0.035 s
2016-09-30 12:12:00 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 3 finished: sortByKey at SparkApplication.java:62, took 0.061892 s
2016-09-30 12:12:00 INFO  [main] org.apache.spark.SparkContext [Logging.scala:54] : Starting job: foreach at SparkApplication.java:63
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Registering RDD 10 (mapToPair at SparkApplication.java:62)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Got job 4 (foreach at SparkApplication.java:63) with 2 output partitions
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Final stage: ResultStage 12 (foreach at SparkApplication.java:63)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Parents of final stage: List(ShuffleMapStage 11)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Missing parents: List(ShuffleMapStage 11)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:62), which has no missing parents
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8 stored as values in memory (estimated size 4.5 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.6 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_8_piece0 in memory on 172.16.106.190:53246 (size: 2.6 KB, free: 912.2 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[10] at mapToPair at SparkApplication.java:62)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 11.0 with 2 tasks
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 11.0 (TID 12, localhost, partition 0, ANY, 5130 bytes)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 11.0 (TID 13, localhost, partition 1, ANY, 5130 bytes)
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 11.0 (TID 13)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_7_piece0 on 172.16.106.190:53246 in memory (size: 2.8 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_3_piece0 on 172.16.106.190:53246 in memory (size: 3.1 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-0] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_4_piece0 on 172.16.106.190:53246 in memory (size: 2.6 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_5_piece0 on 172.16.106.190:53246 in memory (size: 2.5 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 11.0 (TID 12)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-1] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Removed broadcast_6_piece0 on 172.16.106.190:53246 in memory (size: 2.0 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 4 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 4 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13). 1882 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 11.0 (TID 13) in 41 ms on localhost (1/2)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12). 1882 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-0] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 11.0 (TID 12) in 49 ms on localhost (2/2)
2016-09-30 12:12:00 INFO  [task-result-getter-0] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ShuffleMapStage 11 (mapToPair at SparkApplication.java:62) finished in 0.046 s
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : looking for newly runnable stages
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : running: Set()
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : waiting: Set(ResultStage 12)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : failed: Set()
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:62), which has no missing parents
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9 stored as values in memory (estimated size 4.1 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.4 KB, free 912.1 MB)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-3] o.a.spark.storage.BlockManagerInfo [Logging.scala:54] : Added broadcast_9_piece0 in memory on 172.16.106.190:53246 (size: 2.4 KB, free: 912.3 MB)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext [Logging.scala:54] : Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Submitting 2 missing tasks from ResultStage 12 (ShuffledRDD[13] at sortByKey at SparkApplication.java:62)
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Adding task set 12.0 with 2 tasks
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 0.0 in stage 12.0 (TID 14, localhost, partition 0, ANY, 5141 bytes)
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-1] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Starting task 1.0 in stage 12.0 (TID 15, localhost, partition 1, ANY, 5141 bytes)
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 1.0 in stage 12.0 (TID 15)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Running task 0.0 in stage 12.0 (TID 14)
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 1 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Getting 2 non-empty blocks out of 2 blocks
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] o.a.s.s.ShuffleBlockFetcherIterator [Logging.scala:54] : Started 0 remote fetches in 0 ms
2016-09-30 12:12:00 INFO  [Executor task launch worker-0] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15). 1553 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-2] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 1.0 in stage 12.0 (TID 15) in 26 ms on localhost (1/2)
2016-09-30 12:12:00 INFO  [Executor task launch worker-1] org.apache.spark.executor.Executor [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14). 1640 bytes result sent to driver
2016-09-30 12:12:00 INFO  [task-result-getter-3] o.a.spark.scheduler.TaskSetManager [Logging.scala:54] : Finished task 0.0 in stage 12.0 (TID 14) in 31 ms on localhost (2/2)
2016-09-30 12:12:00 INFO  [task-result-getter-3] o.a.s.scheduler.TaskSchedulerImpl [Logging.scala:54] : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2016-09-30 12:12:00 INFO  [dag-scheduler-event-loop] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : ResultStage 12 (foreach at SparkApplication.java:63) finished in 0.032 s
2016-09-30 12:12:00 INFO  [main] o.a.spark.scheduler.DAGScheduler [Logging.scala:54] : Job 4 finished: foreach at SparkApplication.java:63, took 0.124540 s
2016-09-30 12:12:00 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Invoking stop() from shutdown hook
2016-09-30 12:12:00 INFO  [Thread-1] o.s.jetty.server.ServerConnector [AbstractConnector.java:306] : Stopped ServerConnector@6f0b0a5e{HTTP/1.1}{0.0.0.0:4040}
2016-09-30 12:12:00 INFO  [Thread-1] org.apache.spark.ui.SparkUI [Logging.scala:54] : Stopped Spark web UI at http://172.16.106.190:4040
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-3] o.a.s.MapOutputTrackerMasterEndpoint [Logging.scala:54] : MapOutputTrackerMasterEndpoint stopped!
2016-09-30 12:12:00 INFO  [Thread-1] o.a.s.storage.memory.MemoryStore [Logging.scala:54] : MemoryStore cleared
2016-09-30 12:12:00 INFO  [Thread-1] o.apache.spark.storage.BlockManager [Logging.scala:54] : BlockManager stopped
2016-09-30 12:12:00 INFO  [Thread-1] o.a.s.storage.BlockManagerMaster [Logging.scala:54] : BlockManagerMaster stopped
2016-09-30 12:12:00 INFO  [dispatcher-event-loop-3] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [Logging.scala:54] : OutputCommitCoordinator stopped!
2016-09-30 12:12:00 INFO  [Thread-1] org.apache.spark.SparkContext [Logging.scala:54] : Successfully stopped SparkContext
2016-09-30 12:12:00 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Shutdown hook called
2016-09-30 12:12:00 INFO  [Thread-1] o.a.spark.util.ShutdownHookManager [Logging.scala:54] : Deleting directory /private/var/folders/_z/4sz05tlx0c9_lmn2lplzh3w00000gn/T/spark-d143c5f5-01e2-471a-8fdb-9e4bd8e3c28a
